{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "165d2f2d",
      "metadata": {},
      "source": [
        "# LangFuse Online Evaluation\n",
        "\n",
        "- Author: [ranian963](https://github.com/ranian963)\n",
        "- Peer Review:\n",
        "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/16-Evaluations/15-LangFuse-Online-Evaluation.ipynb) [![Open in GitHub](https://img.shields.io/badge/Open%20in%20GitHub-181717?style=flat-square&logo=github&logoColor=white)](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/16-Evaluations/15-LangFuse-Online-Evaluation.ipynb)\n",
        "\n",
        "## Overview\n",
        "\n",
        "This tutorial covers the observation and tracing of LangGraph applications using LangFuse.\n",
        "\n",
        "LangFuse provides a comprehensive logging, debugging, and evaluation framework for LangChain applications.\n",
        "\n",
        "In this tutorial, we will explore how to integrate LangFuse into a LangGraph application and monitor its execution.\n",
        "\n",
        "### Table of Contents\n",
        "\n",
        "- [Overview](#overview)\n",
        "- [Environment Setup](#environment-setup)\n",
        "- [Introduction to LangGraph](#introduction-to-langgraph)\n",
        "- [Introduction LangFuse](#introduction-to-langfuse)\n",
        "- [Online LangFuse Guide](#Online-LangFuse-Guide)\n",
        "- [Implementation and Examples](#implementation-and-examples)\n",
        "\n",
        "\n",
        "### References\n",
        "\n",
        "- [LangChain Documentation](https://python.langchain.com/docs/get_started/introduction)\n",
        "- [LangFuse Documentation](https://langfuse.com/docs)\n",
        "- [LangGraph Documentation](https://python.langchain.com/docs/langgraph)\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3b772b0",
      "metadata": {},
      "source": [
        "## Environment Setup\n",
        "\n",
        "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
        "\n",
        "**[Note]**\n",
        "- `langchain-opentutorial` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials. \n",
        "- You can checkout the [`langchain-opentutorial`](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fac6fcf",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install langchain-opentutorial\n",
        "%pip install langfuse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28e464b6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "from langchain_opentutorial import package\n",
        "\n",
        "package.install(\n",
        "    [\n",
        "        \"langchain\",\n",
        "        \"langchain_community\",\n",
        "        \"langchain_openai\",\n",
        "        \"langgraph\",\n",
        "    ],\n",
        "    verbose=False,\n",
        "    upgrade=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ca4003e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set environment variables\n",
        "from langchain_opentutorial import set_env\n",
        "\n",
        "set_env(\n",
        "    {\n",
        "        \"OPENAI_API_KEY\": \"\",\n",
        "        \"TAVILY_API_KEY\": \"\",\n",
        "        \"LANGFUSE_SECRET_KEY\": \"\",\n",
        "        \"LANGFUSE_PUBLIC_KEY\": \"\",\n",
        "        \"LANGFUSE_HOST\": \"https://cloud.langfuse.com\",\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69a01075",
      "metadata": {},
      "source": [
        "You can alternatively set API keys such as `OPENAI_API_KEY` in a `.env` file and load them.\n",
        "\n",
        "**[Note]** This is not necessary if you've already set the required API keys in previous steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1eec3c3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load API keys from .env file\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv(override=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ecf048d",
      "metadata": {},
      "source": [
        "## Introduction to LangGraph\n",
        "\n",
        "LangGraph is an advanced framework designed for building dynamic, multi-step AI workflows.\n",
        "It enables developers to create complex, structured execution flows for AI applications.\n",
        "\n",
        "- A structured way to build complex workflows\n",
        "- State management capabilities\n",
        "- Integration with various LLM tools and services\n",
        "- Clear visualization of application flow\n",
        "\n",
        "### Basic LangGraph Concepts\n",
        "\n",
        "1. Nodes: Individual processing units\n",
        "2. Edges: Connections between nodes\n",
        "3. State: Data maintained throughout the workflow\n",
        "4. Conditional Logic: Decision making within the graph"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67fadef6",
      "metadata": {},
      "source": [
        "## Introduction to LangFuse\n",
        "\n",
        "LangFuse is an observability platform for LLM-based applications.\n",
        "It provides structured logs, debugging insights, and evaluation capabilities to improve the performance of AI models.\n",
        "\n",
        "### Key Features\n",
        "\n",
        "- **Tracing:** Tracks execution paths in LangGraph.\n",
        "- **Logging:** Stores and analyzes LLM interactions.\n",
        "- **Evaluation:** Benchmarks AI-generated responses.\n",
        "\n",
        "### Why LangFuse?\n",
        "\n",
        "- Provides detailed insights into LLM application behavior\n",
        "- Helps identify bottlenecks and optimization opportunities\n",
        "- Enables data-driven iteration on prompts and workflows\n",
        "- Supports production monitoring and debugging"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6890c3ed",
      "metadata": {},
      "source": [
        "## Online LangFuse Guide\n",
        "\n",
        "To enable online tracking with LangFuse, follow these steps:\n",
        "\n",
        "1. **Create an API Key** on [LangFuse Cloud](https://cloud.langfuse.com/).\n",
        "2. **Set Up Environment Variables** in your `.env` file.\n",
        "3. **Enable Logging and Tracing** in your LangGraph application.\n",
        "\n",
        "The following sections will provide two practical examples of how LangFuse can be used in an AI application.\n",
        "\n",
        "### LangFuse Cloud Pricing\n",
        "LangFuse offers flexible pricing tiers to accommodate different needs, starting with a free Hobby plan that requires no credit card. \n",
        "\n",
        "The pricing structure includes:\n",
        "\n",
        "![LangFuse-Cloud-Pricing](./assets/15-LangFuse-Online-Evaluation-01.png)\n",
        "\n",
        "\n",
        "### Setup and Configuration\n",
        "\n",
        "1. [LangFuse Cloud](https://cloud.langfuse.com/) Site Access\n",
        "   - Navigate to the LangFuse Cloud platform to begin the setup process\n",
        "   \n",
        "2. Create LangFuse Account\n",
        "   - Sign up for a new account using your email or OAuth providers\n",
        "   ![Create LangFuse Account](./assets/15-LangFuse-Online-Evaluation-02.png)\n",
        "\n",
        "3. Create New Organization\n",
        "   - Set up a new organization to manage your projects and team members\n",
        "   ![Create New Organization](./assets/15-LangFuse-Online-Evaluation-03.png)\n",
        "\n",
        "4. Member Settings\n",
        "   - Configure member roles and permissions for your organization\n",
        "   ![Member Settings](./assets/15-LangFuse-Online-Evaluation-04.png)\n",
        "\n",
        "5. Project Creation\n",
        "   - Create a new project to start monitoring your LLM applications\n",
        "   ![Project Creation](./assets/15-LangFuse-Online-Evaluation-05.png)\n",
        "\n",
        "6. Obtain API Keys\n",
        "   - Generate and securely store your public and secret API keys for authentication\n",
        "   ![Obtain API Keys](./assets/15-LangFuse-Online-Evaluation-06.png)\n",
        "\n",
        "7. Dashboard Overview\n",
        "   - Explore the dashboard interface to monitor your application's performance and usage\n",
        "   ![Dashboard Overview](./assets/15-LangFuse-Online-Evaluation-07.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5dc0506b",
      "metadata": {},
      "source": [
        "### Basic Implementation\n",
        "\n",
        "This basic implementation shows:\n",
        "1. Initialize Langfuse\n",
        "2. Creating a simple trace\n",
        "3. Basic logging and generation recording"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00b8d569",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.schema import StrOutputParser\n",
        "from operator import itemgetter\n",
        "\n",
        "from langfuse.callback import CallbackHandler\n",
        "\n",
        "# Environment variables have been set in the previous environment setup section\n",
        "\n",
        "langfuse_handler = CallbackHandler()\n",
        "\n",
        "prompt1 = ChatPromptTemplate.from_template(\"what is the city {person} is from?\")\n",
        "prompt2 = ChatPromptTemplate.from_template(\n",
        "    \"what country is the city {city} in? respond in {language}\"\n",
        ")\n",
        "model = ChatOpenAI()\n",
        "chain1 = prompt1 | model | StrOutputParser()\n",
        "chain2 = (\n",
        "    {\"city\": chain1, \"language\": itemgetter(\"language\")}\n",
        "    | prompt2\n",
        "    | model\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "chain2.invoke(\n",
        "    {\"person\": \"obama\", \"language\": \"english\"}, config={\"callbacks\": [langfuse_handler]}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d7a68f4",
      "metadata": {},
      "source": [
        "#### View traces in Langfuse\n",
        "\n",
        "Example trace in Langfuse: https://cloud.langfuse.com/project/cm71ka0zx07yxad079p1kn1bz/traces/c99361dc-fc41-4152-8ef0-eb7507d01b65\n",
        "\n",
        "![Trace view of simple code in Langfuse](./assets/15-LangFuse-Online-Evaluation-08.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3d78380",
      "metadata": {},
      "source": [
        "## Implementation and Example\n",
        "In this section, we'll look at two examples of using LangFuse.\n",
        "\n",
        "1. Basic LangGraph monitoring: Shows simple trace creation and logging of LLM interactions\n",
        "2. Tool-using agent: Demonstrates how to track an AI agent's interactions with a search tool"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f953a905",
      "metadata": {},
      "source": [
        "### Example 1. Simple chat app with LangGraph\n",
        "\n",
        "*   Build a support chatbot in LangGraph that can answer common questions\n",
        "*   Tracing the chatbot's input and output using Langfuse\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64899bbd",
      "metadata": {},
      "source": [
        "#### Create Agent\n",
        "\n",
        "Start by creating a StateGraph. A StateGraph object defines our chatbot's structure as a state machine. \n",
        "\n",
        "We will add nodes to represent the LLM and functions the chatbot can call, and edges to specify how the bot transitions between these functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8a7ec14",
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Annotated\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    # Messages have the type \"list\". The `add_messages` function in the annotation defines how this state key should be updated\n",
        "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.2)\n",
        "\n",
        "\n",
        "# The chatbot node function takes the current State as input and returns an updated messages list. This is the basic pattern for all LangGraph node functions.\n",
        "def chatbot(state: State):\n",
        "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
        "\n",
        "\n",
        "# Add a \"chatbot\" node. Nodes represent units of work. They are typically regular python functions.\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "\n",
        "# Add an entry point. This tells our graph where to start its work each time we run it.\n",
        "graph_builder.set_entry_point(\"chatbot\")\n",
        "\n",
        "# Set a finish point. This instructs the graph \"any time this node is run, you can exit.\"\n",
        "graph_builder.set_finish_point(\"chatbot\")\n",
        "\n",
        "# To be able to run our graph, call \"compile()\" on the graph builder. This creates a \"CompiledGraph\" we can use invoke on our state.\n",
        "graph = graph_builder.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb73f3b3",
      "metadata": {},
      "source": [
        "#### Add Langfuse as callback to the invocation\n",
        "\n",
        "Now, we will add then [Langfuse callback handler for LangChain](https://langfuse.com/docs/integrations/langchain/tracing) to trace the steps of our application: `config={\"callbacks\": [langfuse_handler]}`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ddde5e9",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langfuse.callback import CallbackHandler\n",
        "\n",
        "# Initialize Langfuse CallbackHandler for Langchain (tracing)\n",
        "langfuse_handler = CallbackHandler()\n",
        "\n",
        "for s in graph.stream(\n",
        "    {\"messages\": [HumanMessage(content=\"What is Langfuse?\")]},\n",
        "    config={\"callbacks\": [langfuse_handler]},\n",
        "):\n",
        "    print(s)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbc6311c",
      "metadata": {},
      "source": [
        "#### View traces in Langfuse\n",
        "\n",
        "Example trace in Langfuse: https://cloud.langfuse.com/project/cm71ka0zx07yxad079p1kn1bz/traces/4dd6a2f4-353c-457c-afcd-1fc7837cf3ad\n",
        "\n",
        "![Trace view of chat app in Langfuse](./assets/15-LangFuse-Online-Evaluation-09.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8798bdbf",
      "metadata": {},
      "source": [
        "#### Visualize the chat app\n",
        "\n",
        "You can visualize the graph using the `get_graph` method along with a \"draw\" method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d332bc5",
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c5defc8",
      "metadata": {},
      "source": [
        "### Example 2. Tool-using agent with LangGraph\n",
        "\n",
        "*   Build an agent that can search and reason about information using ReAct framework and Tavily search tool\n",
        "*   Track the agent's reasoning process and tool usage with Langfuse monitoring"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86022508",
      "metadata": {},
      "source": [
        "#### Import and Create the Search Tool\n",
        "\n",
        "The Tavily Search API tool is designed to facilitate powerful search capabilities within the chatbot. It retrieves comprehensive and reliable search results, making it ideal for answering questions about current events or topics that require external information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52376563",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.tools import TavilySearchResults\n",
        "\n",
        "# Create the Search Tool\n",
        "tool = TavilySearchResults(max_results=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7980ee01",
      "metadata": {},
      "source": [
        "#### Add the Tool to the Tool List\n",
        "\n",
        "* The search tool is added to a list ( `tools` ). In LangChain, multiple tools can be combined to build more advanced workflows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c684d3ef",
      "metadata": {},
      "outputs": [],
      "source": [
        "tools = [tool]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Execute the Tool\n",
        "\n",
        "- The `invoke` method is called to execute the search query \"U.S. Presidential Inauguration\". \n",
        "The search results are returned in JSON format and displayed using the `print` statement.\n",
        "- The results are page summaries that can be used by the chatbot to answer user questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6238e4bd",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(tool.invoke(\"U.S. Presidential Inauguration\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "968878ad",
      "metadata": {},
      "source": [
        "#### Create ReAct Agent\n",
        "\n",
        "After setting up our search tool, we'll create a ReAct agent using LangGraph's prebuilt functionality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "339be3ef",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "model = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
        "graph = create_react_agent(model, tools)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfeaeaba",
      "metadata": {},
      "source": [
        "#### Execute the Agent\n",
        "Now we'll run our agent with LangFuse monitoring enabled. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "806a887e",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langfuse.callback import CallbackHandler\n",
        "\n",
        "# Initialize Langfuse CallbackHandler for Langchain (tracing)\n",
        "langfuse_handler = CallbackHandler()\n",
        "\n",
        "inputs = {\"messages\": \"Search for information about the TED YouTube channel\"}\n",
        "\n",
        "for event in graph.stream(inputs, stream_mode=\"values\", config={\"callbacks\": [langfuse_handler]}):\n",
        "    for key, value in event.items():\n",
        "        print(f\"\\n==============\\nSTEP: {key}\\n==============\\n\")\n",
        "        # display_message_tree(value[\"messages\"][-1])\n",
        "        print(value[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98660c21",
      "metadata": {},
      "source": [
        "#### View traces in Langfuse\n",
        "\n",
        "Example trace in Langfuse: https://cloud.langfuse.com/project/cm71ka0zx07yxad079p1kn1bz/traces/025531e4-137e-4962-839b-3352ec2563c9\n",
        "\n",
        "![Trace view of chat app in Langfuse](./assets/15-LangFuse-Online-Evaluation-10.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b94412f",
      "metadata": {},
      "source": [
        "#### Visualize the chat app\n",
        "\n",
        "You can visualize the graph using the `get_graph` method along with a \"draw\" method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73b23e0b",
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "python3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
