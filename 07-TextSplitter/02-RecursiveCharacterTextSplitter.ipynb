{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "635d8ebb",
      "metadata": {},
      "source": [
        "# 02. RecursiveCharacterTextSplitter\n",
        "\n",
        "- Author: [fastjw](https://github.com/fastjw)\n",
        "- Design: [fastjw](https://github.com/fastjw)\n",
        "- Peer Review : [Wonyoung Lee](https://github.com/BaBetterB), [sohyunwriter](https://github.com/sohyunwriter)\n",
        "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/07-TextSplitter/02-RecursiveCharacterTextSplitter.ipynb) [![Open in GitHub](https://img.shields.io/badge/Open%20in%20GitHub-181717?style=flat-square&logo=github&logoColor=white)](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/07-TextSplitter/02-RecursiveCharacterTextSplitter.ipynb)\n",
        "\n",
        "## Overview\n",
        "\n",
        "This tutorial explains how to use the `RecursiveCharacterTextSplitter`, the recommended way to split text in LangChain.\n",
        "\n",
        "The `RecursiveCharacterTextSplitter` works by taking a list of characters and attempting to split the text into smaller pieces based on that list. It continues splitting until the pieces are sufficiently small.\n",
        "\n",
        "By default, the character list is **['\\\\n\\\\n', '\\\\n', ' \\\", \\\"']**, which means it recursively splits in the following order: **paragraph** -> **sentence** -> **word**. This prioritizes keeping paragraphs, then sentences, then words together as much as possible, as these are considered the most semantically related units.\n",
        "\n",
        "Here's a summary of how it works:\n",
        "1. Splitting is done by a list of characters (**[‘\\\\n\\\\n’, ‘\\\\n’, ‘ “, ”’]**).\n",
        "2. Chunk size is measured by the number of characters.\n",
        "\n",
        "### Table of Contents\n",
        "\n",
        "- [Overview](#overview)\n",
        "- [Environement Setup](#environment-setup)\n",
        "- [Example Usage of RecursiveCharacterTextSplitter](#example-usage-of-recursivecharactertextsplitter)\n",
        "\n",
        "### References\n",
        "\n",
        "- [LangChain: Recursively split by character](https://python.langchain.com/v0.1/docs/modules/data_connection/document_transformers/recursive_text_splitter/)\n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6c7aba4",
      "metadata": {},
      "source": [
        "## Environment Setup\n",
        "\n",
        "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
        "\n",
        "**[Note]**\n",
        "- `langchain-opentutorial` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials. \n",
        "- You can checkout the [`langchain-opentutorial`](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "21943adb",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "!pip install langchain-opentutorial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f25ec196",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "from langchain_opentutorial import package\n",
        "\n",
        "package.install(\n",
        "    [\n",
        "        \"langchain_text_splitters\",\n",
        "    ],\n",
        "    verbose=False,\n",
        "    upgrade=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7f9065ea",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment variables have been set successfully.\n"
          ]
        }
      ],
      "source": [
        "# Set environment variables\n",
        "from langchain_opentutorial import set_env\n",
        "\n",
        "set_env(\n",
        "    {\n",
        "        \"OPENAI_API_KEY\": \"\",\n",
        "        \"LANGCHAIN_API_KEY\": \"\",\n",
        "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
        "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
        "        \"LANGCHAIN_PROJECT\": \"RecursiveCharacterTextSplitter\", \n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4f99b5b6",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa00c3f4",
      "metadata": {},
      "source": [
        "## Example Usage of RecursiveCharacterTextSplitter\n",
        "\n",
        "This example demonstrates how to use the `RecursiveCharacterTextSplitter` to split text into smaller chunks.\n",
        "1. Open the text file `appendix-keywords.txt` and read its contents and store this text in a variable named `file`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "69cb77da",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Open the appendix-keywords.txt file to create a file object named f.\n",
        "with open(\"./data/appendix-keywords.txt\") as f:\n",
        "    file = f.read()  # Reads the contents of the file and stores them in the file variable."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ccb6bf9",
      "metadata": {},
      "source": [
        "2. Display some of the content read from the `file`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "31638667",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Semantic Search\n",
            "\n",
            "Definition: A vector store is a system that stores data converted to vector format. It is used for search, classification, and other data analysis tasks.\n",
            "Example: Vectors of word embeddings can be stored in a database for quick access.\n",
            "Related keywords: embedding, database, vectorization, vectorization\n",
            "\n",
            "Embedding\n",
            "\n",
            "Definition: Embedding is the process of converting textual data, such as words or sentences, into a low-dimensional, continuous vector. This allows computers to unders\n"
          ]
        }
      ],
      "source": [
        "# Output the top 500 characters read from the file.\n",
        "print(file[:500])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b2fc536",
      "metadata": {},
      "source": [
        "3. Now, create a `RecursiveCharacterTextSplitter` with the following parameters:\n",
        "\n",
        "- `chunk_size` = 250 (limits each chunk to 250 characters)\n",
        "- `chunk_overlap` = 50 (allows 50 characters of overlap between chunks)\n",
        "- `length_function` = `len()` (specifies that built-in `len()` function for length calculation)\n",
        "- `is_separator_regex` = `False` (disables regular expression separators)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "1b78d33f",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    # Set the chunk size to very small. These settings are for illustrative purposes only.\n",
        "    chunk_size=250,\n",
        "    # Sets the number of overlapping characters between chunks.\n",
        "    chunk_overlap=50,\n",
        "    # Specifies a function to calculate the length of the string.\n",
        "    length_function=len,\n",
        "    # Sets whether to use regular expressions as delimiters.\n",
        "    is_separator_regex=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9e4d831",
      "metadata": {},
      "source": [
        "4. Use the `text_splitter` to split the text stored in the `file` variable into a list of `Document` objects. This list will be stored in a variable called `texts`.\n",
        "5. Print the first and second documents using `print(texts[0])` and `print(texts[1])`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "0874c14b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "page_content='Semantic Search'\n",
            "============================================================\n",
            "page_content='Definition: A vector store is a system that stores data converted to vector format. It is used for search, classification, and other data analysis tasks.\n",
            "Example: Vectors of word embeddings can be stored in a database for quick access.'\n"
          ]
        }
      ],
      "source": [
        "# Split the file text into documents using text_splitter.\n",
        "texts = text_splitter.create_documents([file])\n",
        "print(texts[0])  # Outputs the first document in the split document.\n",
        "print(\"===\" * 20)\n",
        "print(texts[1])  # Output the second document of the split document."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c026d703",
      "metadata": {},
      "source": [
        "Alternatively, you can also use the `text_splitter.split_text()` function to split the `file` text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a2d22b26",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Semantic Search',\n",
              " 'Definition: A vector store is a system that stores data converted to vector format. It is used for search, classification, and other data analysis tasks.\\nExample: Vectors of word embeddings can be stored in a database for quick access.']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Splits the text and returns the first two elements of the split text.\n",
        "text_splitter.split_text(file)[:2]"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "3.11.9",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
