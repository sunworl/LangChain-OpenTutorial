{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "059756b7",
      "metadata": {},
      "source": [
        "# Deploy on LangGraph Cloud\n",
        "\n",
        "- Author: [JoonHo Kim](https://github.com/jhboyo)\n",
        "- Design: []()\n",
        "- Peer Review :\n",
        "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/06-DocumentLoader/04-CSV-Loader.ipynb) [![Open in GitHub](https://img.shields.io/badge/Open%20in%20GitHub-181717?style=flat-square&logo=github&logoColor=white)](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/06-DocumentLoader/04-CSV-Loader.ipynb)\n",
        "\n",
        "\n",
        "## Overview\n",
        "**LangGraph Cloud** is a cloud-based framework designed to simplify the development, deployment, and management of graph-based workflows for AI applications. It extends the functionality of **LangGraph** by providing a scalable, distributed, and user-friendly environment to build complex AI agents, workflows, and pipelines.\n",
        "\n",
        "With **LangGraph Cloud**, you can:\n",
        "- Handle large workloads with horizontally-scaling servers, task queues, and built-in persistence.\n",
        "- Debug agent failure modes and quickly iterate in a visual playground-like studio.\n",
        "- Deploy in one-click and get integrated tracing & monitoring in LangSmith.\n",
        "\n",
        "This tutorial will guide you through the key features and components of LangGraph Cloud, including:\n",
        "- Setting up **LangGraph Cloud**: How to create an account, configure your workspace, and deploy your first workflow.\n",
        "- Deploying workflows: Deploying workflows using LangGraph Cloud.\n",
        "- Using **LangGraph Studio**: How to connect to the Web UI **LangGraph Studio** and test the assistant.\n",
        "- Testing the API: How to use send messages to the assistant using the **Python SDK** and verify the message data using **Rest API**.\n",
        "\n",
        "By the end of this tutorial, you will be equipped with the knowledge to effectively utilize **LangGraph Cloud** for building and managing AI workflows in a scalable and efficient manner.\n",
        "\n",
        "Now, let's dive in and explore how to boost performance with **LangGraph Cloud**! ðŸš€\n",
        "\n",
        "\n",
        "\n",
        "### Table of Contents\n",
        "\n",
        "- [Overview](#overview)\n",
        "- [Environment Setup](#environment-setup)\n",
        "- [Prerequisites](#prerequisites)\n",
        "- [Setting up a new repository on GitHub](#setting-up-a-new-repository-on-github)\n",
        "- [Deployment to LangGraph Cloud](#deployment-to-langgraph-cloud)\n",
        "- [Using LangGraph Studio on the web](#using-langgraph-studio-on-the-web)\n",
        "- [Testing the API](#testing-the-api)\n",
        "\n",
        "### References\n",
        "\n",
        "- [Deploy on LangGraph Cloud](https://langchain-ai.github.io/langgraph/cloud/quick_start/#deploy-to-langgraph-cloud)\n",
        "- [React Agent](https://github.com/langchain-ai/react-agent)\n",
        "- [LangGraph Studio](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/#cloud-studio)\n",
        "\n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "923a83b4",
      "metadata": {},
      "source": [
        "## Environment Setup\n",
        "\n",
        "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
        "\n",
        "**[Note]**\n",
        "- `langchain-opentutorial` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials. \n",
        "- You can checkout the [`langchain-opentutorial`](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "8e8ad1ef",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install -qU langchain-opentutorial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "446f6eba",
      "metadata": {},
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "from langchain_opentutorial import set_env\n",
        "\n",
        "# Attempt to load environment variables from a .env file; if unsuccessful, set them manually.\n",
        "if not load_dotenv():\n",
        "    set_env(\n",
        "        {\n",
        "            \"OPENAI_API_KEY\": \"\",\n",
        "            \"ANTHROPIC_API_KEY\": \"\",\n",
        "            \"LANGCHAIN_API_KEY\": \"\",\n",
        "            \"LANGCHAIN_TRACING_V2\": \"false\",\n",
        "            \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
        "            \"LANGCHAIN_PROJECT\": \"LangGraph-Cloud\",\n",
        "        }\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70361e4a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "from langchain_opentutorial import package\n",
        "\n",
        "package.install(\n",
        "    [\n",
        "        \"langgraph-sdk\",\n",
        "    ],\n",
        "    verbose=False,\n",
        "    upgrade=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5877653",
      "metadata": {},
      "source": [
        "\n",
        "## Prerequisites\n",
        "Before we start, ensure we have the following:\n",
        "\n",
        "- [GitHub Account](https://github.com/join)\n",
        "- [LangSmith API key](https://docs.smith.langchain.com/administration/how_to_guides/organization_management/create_account_api_key/)\n",
        "- [Anthropic API key](https://console.anthropic.com/settings/keys)\n",
        "- [Tavily API key](https://app.tavily.com/home)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16944702",
      "metadata": {},
      "source": [
        "## Setting up a new repository on GitHub\n",
        "\n",
        "To deploy a **LangGraph** application on **LangGraph Cloud**, your application's code must be stored in a **GitHub** repository. \n",
        "You can deploy any **LangGraph** applications to **LangGraph Cloud** with ease. \n",
        "\n",
        "For this guide, we'll use the pre-built **Python** [`ReAct Agent`](https://github.com/langchain-ai/react-agent) template. You can go to **GitHub** and fork the repository.\n",
        "This [`ReAct Agent`](https://github.com/langchain-ai/react-agent) application requires API keys from **Anthropic** and **Tavily**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d692d28f",
      "metadata": {},
      "source": [
        "## Deployment to LangGraph Cloud"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69985a2a",
      "metadata": {},
      "source": [
        "1. After logging in **[LangSmith](https://smith.langchain.com)**, you can click the **LangGraph Platform** menu at the bottom of the left sidebar.\n",
        "\n",
        "\n",
        "    <img src=\"./assets/12-LangGraph-cloud-sidebar-menu.png\" width=\"280\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Click **+ New Deployment** button at the bottom of the page and then you can follow the steps below for creating a new deployment.\n",
        "    \n",
        "    * Select **Github react-agent** repository from the drop-down menu.\n",
        "    * Write the deployment name in **Name** field.\n",
        "    * Select Git branch. `main` is default.\n",
        "    * Langgraph config file is `langgraph.json` as default. You can also select another file.\n",
        "    * Select **Development type**.\n",
        "    * Write **Environment Variables**. In this tutorial, we will use **ANTHROPIC_API_KEY** and **TAVILY_API_KEY**.\n",
        "    * Click **Submit** button at the upper right corner. It takes a few minutes to build the application.\n",
        "\n",
        "    <img src=\"./assets/12-LangGraph-cloud-create-deployment-1.png\" width=\"1150\">\n",
        "        \n",
        "\n",
        "\n",
        "3. Now you can see the deployment status on the **Overview** section.\n",
        "\n",
        "    <img src=\"./assets/12-LangGraph-cloud-deployment-status.png\" width=\"500\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d38567d",
      "metadata": {},
      "source": [
        "## Using LangGraph Studio on the web"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e081f153",
      "metadata": {},
      "source": [
        "Once your application is deployed, you can test it in **LangGraph Studio** on the web.\n",
        "\n",
        "You can find the **LangGraph Studio** text and **Endpoint URL** at the bottom of the page. Let's click the **LangGraph Studio** text to copy the clipboard.\n",
        "\n",
        "<img src=\"./assets/12-LangGraph-cloud-langgraph-platform.png\" width=\"1150\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77254676",
      "metadata": {},
      "source": [
        "Now you can test your LangGraph application in **LangGraph Studio** on the web.\n",
        "\n",
        "<img src=\"./assets/12-LangGraph-cloud-langgraph-studio.png\" width=\"1150\">\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dded6a30",
      "metadata": {},
      "source": [
        "##  Testing the API"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0415f5c",
      "metadata": {},
      "source": [
        "Now we will send messages to the assistant using the **Python SDK**. you can also use **JavaScript SDK** or **Rest API**.\n",
        "\n",
        "Prior to this, we need to install the **langgraph-sdk** package.\n",
        "```python\n",
        "pip install langgraph-sdk or poetry add langgraph-sdk\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ea5aeaf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'run_id': '1efe7c2f-a184-6b7e-acdf-e9f1899cd49c', 'attempt': 1}\n",
            "{'call_model': {'messages': [{'content': 'Certainly! I\\'d be happy to tell you how to say \"hello\" in French. The most common way to say \"hello\" in French is:\\n\\n\"Bonjour\"\\n\\nThis is a universal greeting that can be used at any time of day and in both formal and informal situations. It literally translates to \"good day\" in English.\\n\\nThere are also other ways to say hello in French depending on the time of day or the level of formality:\\n\\n1. \"Salut\" - This is a more casual way to say hello, similar to \"Hi\" in English.\\n2. \"Bonsoir\" - This means \"good evening\" and is used in the evening hours.\\n3. \"AllÃ´\" - This is typically used when answering the phone, similar to \"Hello\" in English when picking up a call.\\n\\nIs there anything else you\\'d like to know about French greetings or the French language?', 'additional_kwargs': {}, 'response_metadata': {'id': 'msg_0182hjEdNCU3CPKN2z4qXCxh', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 430, 'output_tokens': 204}}, 'type': 'ai', 'name': None, 'id': 'run-44abc770-306f-4332-adad-6f1410459451-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 430, 'output_tokens': 204, 'total_tokens': 634, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}}}]}}\n"
          ]
        }
      ],
      "source": [
        "from langgraph_sdk import get_client\n",
        "\n",
        "client = get_client(url=\"{your_endpoint_url}\", api_key=\"{your_langsmith_key}}\")\n",
        "\n",
        "async for chunk in client.runs.stream(\n",
        "    None,  # Threadless run\n",
        "    \"agent\", # Name of assistant. Defined in langgraph.json.\n",
        "    input={\n",
        "        \"messages\": [{\n",
        "            \"role\": \"human\",\n",
        "            \"content\": \"say hello in french\",\n",
        "        }],\n",
        "    },\n",
        "    stream_mode=\"updates\",\n",
        "):\n",
        "    print(chunk.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "949b65e4",
      "metadata": {},
      "source": [
        "Now, you can verify the message data.\n",
        "\n",
        "If you append `/docs` to the end of the **Endpoint URL** and enter it in a web browser, you can check the web API. We can refer to this document and use API testing tools like Postman or Scalar to conduct tests.\n",
        "\n",
        "ex) `GET https://{{endpoint_url}}threads/{{thread_id}}/history`\n",
        "\n",
        "<img src=\"./assets/12-LangGraph-cloud-web-api-1.png\" width=\"650\">\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "langchain-opentutorial-nHTobcyW-py3.11",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
