{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conversation Summaries with LangGraph\n",
        "\n",
        "- Author: [Junseong Kim](https://www.linkedin.com/in/%EC%A4%80%EC%84%B1-%EA%B9%80-591b351b2/)\n",
        "- Peer Review: \n",
        "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/03-OutputParser/02-CommaSeparatedListOutputParser.ipynb) [![Open in GitHub](https://img.shields.io/badge/Open%20in%20GitHub-181717?style=flat-square&logo=github&logoColor=white)](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/03-OutputParser/02-CommaSeparatedListOutputParser.ipynb)\n",
        "\n",
        "## Overview\n",
        "\n",
        "One of the most common use cases of conversation persistence is keeping track of a conversation's history. By summarizing and referencing past messages, we can maintain essential context without overloading the system with the entire conversation. This becomes especially important for long conversations, where a large context window can lead to increased computational costs and potential inaccuracies. \n",
        "\n",
        "In this tutorial, we will explore how to summarize a conversation and integrate that summary into a new conversation state while removing older messages. This approach helps manage the conversation length within a limited context window, preventing inadvertent increases in cost or inference time.\n",
        "\n",
        "**Key Steps:**\n",
        "\n",
        "1. Detect if a conversation is too long (e.g., based on the number of messages).\n",
        "2. If it exceeds a threshold, summarize the conversation so far.\n",
        "3. Remove older messages and store only the summary (plus the most recent messages).\n",
        "\n",
        "This tutorial will guide you through setting up a conversation flow that automatically summarizes older messages and retains only the recent conversation turns and the summary.\n",
        "\n",
        "![](./assets/12-conversation-summaries-with-langgraph_visualize.png)\n",
        "\n",
        "### Table of Contents\n",
        "- [Overview](#overview)  \n",
        "- [Environment Setup](#environment-setup)  \n",
        "- [Checking the Conversation Length](#checking-the-conversation-length)  \n",
        "- [Summarizing and Managing the Conversation](#summarizing-and-managing-the-conversation)  \n",
        "- [Building Graph Workflow](#building-graph-workflow)  \n",
        "- [Running Workflow](#running-workflow)\n",
        "\n",
        "### References\n",
        "\n",
        "- [LangGraph](https://www.langchain.com/langgraph) \n",
        "- [LangChain ChatOpenAI API reference](https://python.langchain.com/docs/integrations/llms/openai/)  \n",
        "- [LangSmith](https://smith.langchain.com)\n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Environment Setup\n",
        "\n",
        "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
        "\n",
        "**[Note]**\n",
        "- `langchain-opentutorial` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials. \n",
        "- You can checkout the [`langchain-opentutorial`](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install langchain-opentutorial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "from langchain_opentutorial import package\n",
        "\n",
        "package.install(\n",
        "    [\n",
        "        \"langsmith\",\n",
        "        \"langchain\",\n",
        "        \"langgraph\",\n",
        "        \"langchain_core\",\n",
        "        \"langchain_openai\",\n",
        "        \"langchain_community\",\n",
        "        \"IPython\",\n",
        "    ],\n",
        "    verbose=False,\n",
        "    upgrade=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment variables have been set successfully.\n"
          ]
        }
      ],
      "source": [
        "# Set environment variables\n",
        "from langchain_opentutorial import set_env\n",
        "\n",
        "set_env(\n",
        "    {\n",
        "        \"OPENAI_API_KEY\": \"\",\n",
        "        \"LANGCHAIN_API_KEY\": \"\",\n",
        "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
        "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
        "        \"LANGCHAIN_PROJECT\": \"12-Conversation-Summaries-with-LangGraph\",\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can alternatively set `OPENAI_API_KEY` in `.env` file and load it. \n",
        "\n",
        "[Note] This is not necessary if you've already set `OPENAI_API_KEY` in previous steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv(override=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Checking the Conversation Length\n",
        "\n",
        "Below, we set up our custom `State` to store both messages and summaries. We'll also define a helper function in a **separate cell** to determine if the conversation has exceeded a certain length.\n",
        "\n",
        "- The `State` class extends `MessagesState`, holding `messages` and `summary`.\n",
        "- We initialize a `ChatOpenAI` model with the name `gpt-4o-mini`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Literal, Annotated\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import SystemMessage, RemoveMessage, HumanMessage\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.graph import MessagesState, StateGraph, START\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "# Set up an in-memory storage for conversation states\n",
        "memory = MemorySaver()\n",
        "\n",
        "\n",
        "# We'll store both the conversation messages and the summary in the state\n",
        "class State(MessagesState):\n",
        "    messages: Annotated[list, add_messages]\n",
        "    summary: str\n",
        "\n",
        "\n",
        "# Initialize the LLM model for conversation\n",
        "model = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here is a separate code cell for the `should_continue` function, which checks if the conversation has more than 6 messages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langgraph.graph import END\n",
        "\n",
        "\n",
        "def should_continue(state: State) -> Literal[\"summarize_conversation\", END]:\n",
        "    \"\"\"\n",
        "    Check if the conversation is too long (over 6 messages).\n",
        "    If it is, move to the 'summarize_conversation' node.\n",
        "    Otherwise, end the conversation.\n",
        "    \"\"\"\n",
        "    messages = state[\"messages\"]\n",
        "    if len(messages) > 6:\n",
        "        return \"summarize_conversation\"\n",
        "    return END"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summarizing and Managing the Conversation\n",
        "\n",
        "When the conversation exceeds the threshold, we summarize it and remove older messages to preserve only a recent segment and the overall summary. We also create a node (`ask_llm`) to handle new messages, optionally including the existing summary.\n",
        "\n",
        "- `ask_llm` checks if a summary exists and prepends it as a `SystemMessage` if so."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ask_llm(state: State):\n",
        "    \"\"\"\n",
        "    If a summary of the conversation already exists, we include it as a\n",
        "    system message. Otherwise, we just use the existing messages.\n",
        "    \"\"\"\n",
        "    summary = state.get(\"summary\", \"\")\n",
        "\n",
        "    if summary:\n",
        "        system_message = f\"This is the conversation summary so far: {summary}\"\n",
        "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
        "    else:\n",
        "        messages = state[\"messages\"]\n",
        "\n",
        "    response = model.invoke(messages)\n",
        "    return {\"messages\": [response]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- `summarize_conversation` either creates or extends a summary and removes older messages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def summarize_conversation(state: State):\n",
        "    \"\"\"\n",
        "    Summarize the conversation in English.\n",
        "    If an existing summary exists, extend it with new messages.\n",
        "    Delete older messages to reduce context usage,\n",
        "    keeping only the last two messages.\n",
        "    \"\"\"\n",
        "    summary = state.get(\"summary\", \"\")\n",
        "\n",
        "    if summary:\n",
        "        summary_message = (\n",
        "            f\"This is the conversation summary so far:\\n{summary}\\n\\n\"\n",
        "            \"Please extend the summary by incorporating any new messages.\"\n",
        "        )\n",
        "    else:\n",
        "        summary_message = \"Please create a concise summary of the conversation so far.\"\n",
        "\n",
        "    messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n",
        "    response = model.invoke(messages)\n",
        "\n",
        "    # Remove older messages, except the last two\n",
        "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
        "\n",
        "    return {\"summary\": response.content, \"messages\": delete_messages}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Building Graph Workflow\n",
        "\n",
        "Here, we construct a `StateGraph`, add our nodes, and compile the application. We also use `visualize_graph(app)` to see how the workflow is structured.\n",
        "\n",
        "- Use `StateGraph` to define nodes and edges.\n",
        "- Use `visualize_graph(app)` to see the workflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build the workflow graph\n",
        "workflow = StateGraph(State)\n",
        "\n",
        "# Add nodes\n",
        "workflow.add_node(\"conversation\", ask_llm)\n",
        "workflow.add_node(summarize_conversation)\n",
        "\n",
        "# Define edges\n",
        "workflow.add_edge(START, \"conversation\")\n",
        "workflow.add_conditional_edges(\"conversation\", should_continue)\n",
        "workflow.add_edge(\"summarize_conversation\", END)\n",
        "\n",
        "# Compile with memory checkpoint\n",
        "app = workflow.compile(checkpointer=memory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below is an example code snippet that visualizes the current workflow graph. We define custom node styles for the graph and then use IPython utilities to display the rendered image inline. The `NodeStyles` data class customizes fill colors, stroke styles, and overall appearance of the nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQwAAAFNCAIAAAB66sYNAAAAAXNSR0IArs4c6QAAIABJREFUeJzt3XdcU2fbB/ArJGQR9gh7CggKLhTUqqioqKB1W1tXHXV0aKsdjsfRapfWWts6qrW2WrWts1atWxGcKLI3SFhJIISQkJ28f8SXh0dGQJMcAtf34x/hjDtXgj/u+yTn3Iek1WoBIdQyC6ILQKijw5AgpAeGBCE9MCQI6YEhQUgPDAlCepA3btxIdA3IwLQAl3klT2qrRErFVX4pzYLsTGPcE1R28McMMtmJykgTVdepVA5UGtHv4n9hT9J5nKkofC/1lkStEirlKbVV1QpZvVql1KjFKqVZPK5TqWqU8kxRzRFO9hV+qVqrTRdVE/2mAgCQ8MvETqBMKrGj0n4uzoiwZwex7Igux2AucJ/er+FuCY2yplAJLANDYt5KpHU78lLe7tbLjtD/RsYjUSsBSBYAJBLJg25FSA043DJjGtBm1wnXdO/fWRMCAFZkSysyhWpB/qEw9Wl9HSE1YE9irg5zcsazfTXQhX59j2v5I5w8LUgkEz8v9iRm6TAnR63VdKmEAEAfW+ckQUWRRGTi58WexPxoAWqVcnVX/cXtLUqf6B7Qw9reZM+IITEzVQrZraqyYU4eRBdCpFqlwt/KxmRPh8MtM7OzIKW7Cf+IdkxUC4sqhdRkT4chMSdCpXy2V3c2jUl0IQRjkCnf5KVwZGLTPB2GxJwwyBRHKt1kT6dWq5NuXX2ZAfnLt9CSsa4+GbUCgzfbLIppnga9vByxcG9R+trgCJM945oPFpc8LRg0dCSBLbQk1NrBimJp8GabhT2J2UgSVIbbOpnyGTPSHoX16vcCO6rV6pdsoS0e1HC58nojNd4YhsRszPDoFufqa4yWlUrl7p1bJ4zqGx0ZsPTNyXk5GeK62sgwVz6v4syJI5FhrqvemavbUiIR7/x6Q9zIPoN6e4yNDlu7alGtsAYA/jp6MDLM9c7t6wteHze4j2fircsttWBAZTLJdX6ZwZttCodbZoMEYKSvmvd+/+XRX/csWv6hnZ3DP2eOObm4kimWS99bs3vn1g1bdrl7ejs5uwJAfb1k2YIpvMryhUs+cHP3OvXXb1f+/fvj/3wNAEVFuWQyed8PX7319kdKlaJvvygLMqVpC4YVwrIvNMkXixgS8yBSKZY+vvFdr6HGaPxu4vXgkPB5C98FgFenvqFbqFapLC0tR4191dLy2dB/764vC/Oyf/3zsp9/EADcvHHRw9PH2sYOAIoKcml0xhc79rNd//sFTtMWDMuTwQoxyafhONwyD/VqlbXRjlMDg0Mz0h7t/f5LuVzWsDA7MzUgKLTh/3etsObkH4fGTZimS4hug+6h4brHRQW50SPHNk5I0xYMTqHVXOCVGKnxxjAk5sGVxtwW9oqRGl+1ZuuUmfN++WnntPjB6anJuoXZmU8aMgAA9+8mKBTy0WMn6X5UKpWFuVnBIeG6/Aiq+aE9+zzX7HMtGJxMrb5dXW689htgSMyDWqutUsjasOGLsLKy/nDtFweO/FMnqv1u+yYAEFTzedyK7t3DGrYp5RQBgLuHt+7H1Ef3FEpFcEgYABQW5ACAf0Bw4zabtmBwliRStKOn8dpvgCExD2QSaUPWXY0RWlYoFboHoT37BHQLViqUAFCQlwUATuz/Hm3rRk2W1GcXrhz//QAAsN3cAaC4IBcA/AKCGjfbtAWDY5ApsWxv47XfAA/czYa/lW2lTOJu6KvzDu7d8STlwajYiZziwrQnyavWbAUAFssGAH4/tEcsElmQyWPGTQrvPQAADu3fNXnGnHOnjt28dgEApPUSACgsyLWzd3BwdG7cbNMWDFs2AGTWCTRarQnO9cTZUsxGtJOHJcnwPX92VtrDu7eu/vu3sEaweNnqqa/NBwBnF1duZdmdhGtJt6+xXd0jBw5ju7ozmMy/Tx89+cevarXqtTmL7yZeD+3Zp3to+O+/7rG1tYt7dWbjZpu2YPDKL/M57gyWN8Pa4C0/B0+VNxv1alWlvN62816p2153BZWxbB+y8S9UxJCYk/dSb60M7GNNbvFD1ZkTh/J4lU2Xh/Xqm/bkUdPldnb2Jy/cM3SZzRDX1U4Y3b/ZVXYODkJBM6cqDhsxZsOWXa20aWdJM0FCMCRmJlFQIVDIBzm0eDTMrSxTq9RNl5MsSFpNM79oMpnMdjPF9VsajaayvLTZVUqVwrK57pHBZNo7tHiu2rHSvAlufl4MlkHLbB6GxMzI1CqJWkV0FQRLFVXfE1R+HGSsUyefgyExM/mS2rTa6qFO7kQXQiQtaB2pDJNNmoLfk5iZbla2XHl9oqCZA48uolQqVmu1ppxWCHsSs1SnUtSplDQLMtGFmNpVfqlaq33NM9CUT4ohMVePhXyxRhXK6kKTQtQqFRQLkgm+GHkODrfMVR8754cCLt+Ek4YQ6zAnx9fK2vQJwZCYt5XderMoVAqJlC4y0ZQIhCAB6eOMpKFOHhbGuupMXwE43DJ3WoCtOQ8tSRYLfEM1nejPnkStTKyutKZYjmP7mH7+38bw3C2zRwIY6uTuw7R2pjFSaquOl+XVqZT+VjZ8hTRHXCvXqO0saXy5NF0kUGm1HfxxqVR8r4Zbo5T7MK2v8UstSBbjXH0sLQgOfqf5u9PVeTJYZBLpFUe31zyDfJnW9lSaQqPJFdeUycQ2llSRWnG/hmuQxwnckm8OHTBsm88eU6gStYoE0M3K1oZCnekZNMOjG70DfIKHwy3UPhUVFYsWLTp37hzRhZgO9iQI6YEhQUgPDAlqHxKJFBAQQHQVJoUhQe2j1WoLCgqIrsKkMCSo3WxsTHcDnY4AQ4LaTSQy9V0LiYUhQe1DIpFcXY04UVAHhCFB7aPVaisru9bVLBgS1G5BQUFt2KrzwJCgdsvNzSW6BJPCkCCkB4YEtZu9fRe6HBJDgl5ETU0N0SWYFIYEtZujoyPRJZgUhgS1W3V1NdElmBSGBCE9MCSo3fz8/IguwaQwJKjdioqKiC7BpDAkCOmBIUHthqelIKQHnpaCEPofGBLUPiQSKTg4uA0bdh4YEtQ+Wq02JyeH6CpMCkOCkB4YEtQ+OKUQQnrglEIIoedhSFC74bxbCOmB824hpAeeBYyQHngWMELof2BIULu5uLgQXYJJYUhQu/F4PKJLMCkMCWo3vJ4EIT3wehKE9MCeBCE9sCdBSA93d3eiSzApklarJboGZAZmz54tFAotLCxUKlVNTY2TkxOJRFIoFBcuXCC6NKPDngS1yfTp06urq8vKyrhcrkKhKC8vLysrs7DoEv9/usSLRC8vPj7ex8en8RKtVtuvXz/iKjIdDAlqq1mzZtFotIYf2Wz23LlzCa3IRDAkqK3i4+M9PT11j7Va7YABA7rIdbwYEtQOc+bMsbKy0nUjs2fPJrocE8GQoHYYP368l5dXl+pGAIBCdAFdnQa0JfV1ZbJ6jUZDdC1tEjlvFu/vv3tOm5hQVU50LW1CJZN9mNauNOYLt4DfkxDpCo9zprJQpFR2Y9nWKuREl9M52VPpabXV3kzrRX49Aq1sX6AFDAlhLvCeXuFypnh0wyGvCdSplIdKsrb2GOTNYLV3X/wFEeNmVfm/lZxpmBBTsaZYvu0fvjL1Vo2y3T02/o6IcbI8P97Nl+gqupwJbv4Hn2a2dy8MCQFEKkVJfZ0VGT81MTUHKi21tt23DsaQEKBSVu/D7Frzu3UQDpZ0LbT7KBxDQow6tZLoEroiLWir5DJSO/fCkCCkB4YEIT0wJAjpgSFBSA8MCUJ6YEgQ0gNDgpAeGBKE9MCQIKQHhgQhPTAkCOmBIUEmpVQq7l27qJDLGpYIq/jvvTr8+/UrCa2rNXi2NjKptbNfLX9auPfSPSqNrltSzaus5lYQXVdrMCTIpKQSyXNLAkLDVu/4ycm1407CjSExG5z8nJMHfshOuS+XyTx8A+LnLB4wfAwAlBUXHPthW9aj+xqNOiA0fNri94J69QOAC8d+ObLzizdWfJL479ny4kI7J5cx094YPW02AGxZPifr0f3F678YOu5V3UxzH0wdzSvnfHbopG9QaK2g+vjubx7fviqT1Hv4B8bNXhQ1MrahwX5DY+rFooLMVDqdsf2vS2KR6LcdW7IePSBZWPh37zH7/bUevgGcgtwDn68vLcpXqVSeft3i5yyKHBELAO9PHVVTxQWAt0ZHAsCS/3zp7O7x6ZI3AMA7sPvWX0/rivnn95+vnz5eza2wtXeKGj1+6qJ3LKk0AFgU0z8wrJezu2fyrWsKmSwovM+cD9a5uHsZ+53HYxLzkJv2+D8LZzy4cYnJsvHp1r2suKA4OwMA+OWlmxbPenz7OtvTxycwJOvR/a3vzCvITGvY8fC3n9PozMgRY0UCwa/fbEn6928AGDX1dQC4feG0bpv0B0m8ck5wr36+QaHiWuGmxTNvnTvBZNn4hYaVFeZ9v27FtTPHGxpMvnWlrkYQNXJc9IRpDCvr3Zs+fJRwzdXbOyisd1FOBsOKBQBMa2tuOccnKMTTr1txTsb361YWZqYDQJ/Bwy1pdACIGDYqKmass7sHy9Y+NCKq8Ss9vPPzY99/Laqp6d67v1Kl+Ofw/u/Xf9CwNvXu7TuXL4RHDfHw75aSdHP7B0tUKpWx33zsSczDL19vUsplE+cvnbb4PQCo5lUwrKwB4OSBH+rrakdMmvHmh5sA4MyhPX/u+fbETzs/3LFft+OgMfHLNn4NABHRo75ZvfTGuZODxsT3Gxrj4Oya+fBuVWWZk6vH9TN/AsDo6bMB4NTBH3llnBGTZsxfvZFEInEKctfNm/zH7h3D4qbqGnR299z8859UOkP3Iyc/FwDe2/qdk6uHrL6ezmQCgKOL24//JJJIpIb+5961C/6hPWevXHP/2r81ctmitZ9ZWT+b3Wf2ijWfvDFB95hXzrn0x29UOv2zQyfZHl51wpqP34hPvnUlP+NJtx69dNt8euAPtpcPAKyfP6UoO6MgIyW4V4RR33zsScyAqEZQkpfNYLImzV+mW+Lo4sa0YgFA+v0kABg99Q3d8mHjpwBAdsrDhn2d/3+s79+9JwDwyzkAQCaTR0yaAQC3L/4tqhE8Srjq6OIWMWwUADxKuAYAsvr6o7u++v27LxP+OcWwYolrhbzSEl07fQYPb0gIAPR5JRoAvl65OOnfvy3/fzpthUx6/siBT2ZPXDQy4sRP3wEAr4zTllea8eCOVqvtPXAY28MLAKzt7PsOGQEAOY8fNGzj6Oahe+DbvQcAcMtKX+7d1Q97EjMgrhUCgCPblWJp2WRVDQDYOTrrfrS2dwAAhUymbDLVnSWNCgAqxbPLhodPnH764I8J509RyGSVUhkzZRaZTAaAmio+AOhGZY1R6c8CwGD+z1SICz/ezLCyun7mzx83rj59cPeqb/a6uHvtXPvek6RbTm4e/UeMEdVUpyTekMvq2/JK64TCxi8HAGztHABAXFfbdGMqlQ4AaqWiLS2/DAyJGaAxGQAgFFRptVrdGKYBy9a+popbW1PNsrUDAGEVFwDoTKbuSLcVtg6O/YePuXPp3JlD+yxp9OETp+mWM1kskUD+1dHz7r7+bamNSmfMX71x3KwFP3+xIeNh0uFvP3/9vU+eJN1ycHb98sjfNAYz58nDlMQbz82BqNU0PxmDtZ0dAIiE/53QRFDF173MthRjJDjcMgMOzq52Ti7iWuH5owd1S2qrq7hlHAAIjRgAANfP/KFb/u8fhwEgtF9Uq+09ozt8l0rqBo+J12UMAEL69NcdmSiVCgBQKZWNPwZoSsDnKmRStofXzOXvA0BFSZGsXgwAto6ONAYTAPJSHwOAWv1spmOGlRUAlJcU6b5YfK610L6RAJCSdKuaVwEAAn7lwxuXASC0X2T73zaDwZ7EDJBIpBlLP9j76UdHd3119cRRazt7TmFu3yEj3968feLcpQ9vXrl47FD244ckEhRlZ1CotMkL325Ls0FhfXyDexTnZIyZ9kbDwklvLk9Junnn0rnM5Lsu7l5cTjGJTN5x4krDd3/P+WP3N2n3E7v16FX+tBAAQvoOcPP2s7Z3KMrO2LJ8DoVimf4gCQC4JcW6bjAwvG/508Jt77/F9vL2CghevHZL49bYXj7RE6bdOPvnJ2+86hscUpyTVS8WRcWM8wvu8dLv4ovDnsQ8DBk3ccUXuwJCwwVVvLLifDcvv/DIwQDg7uu/7sffevYfVFFSWFZcENovct2Pv/oGhbax2Zgpr4X0HeDVLbhhiad/4Po9R3oPGqaQygqz0uhM1uAxE7Qtz3jv7hNAsaQ+TrwhlUhGTXl91tsfUWn0lV/+EBAanp+Ryi0tWfDx5kFj4usl4tKCXACYvmRl70HD1GplxdNCWweHpg3OW71h8sK3mSxWTspDBoMZP2fxW//54oXeM4PBCbMJkCsWfpn3aJFPW/8rI0NRaTWf5yT/Myi+XXthT4KQHhgShPTAkCCkB4YEIT0wJAjpgSFBSA8MCUJ6YEgQ0gNDgpAeGBKE9MCQIKQHhgQhPTAkCOmBISGApQXJ0VLPlYPIGDQAASzb9u6FISGAH9P2SW0VXqJgeuVSyQv8j8eQEGOki1ehRER0FV1OhUwyxMmjvXthSIixKrDvqfKCOpWS6EK6kPs13CqFdIp7QHt3xCsTCSNRq+Y+vDzcxcOaTHWhMTSAvwjj0JLKZWKhUlEuE38TNuQFGsCQEOxYaV5KLV8D2gppm2amapZCoRCJRE5OTgYtrUPg8/mOTk4W/zuRUrv4WtlQSKT+9uxxbJ8XawFD0hmsW7du3bp1dHrzE5qYtfT09IsXL65atYrAGjAkZiw3NzclJWX69OlEF2IKe/bsWbhwIYVCwCRYeOBuroRC4YYNG8aNG0d0ISYyZMiQuLg4Qp4aexLzU1lZyePxvL297ezsiK6FAJcvXx41apQpnxF7EjNTVVW1YMGCgICArpkQAPDy8hoxYoQpnxF7ErOhVqslEolIJPL09CS6FoJJJBIrK6ucnJzg4OA2bP6ysCcxD+np6QMHDmQwGJgQALCysgIACoUye/ZshcLot17AkJiHxMTE+/fvWza5P0lXFhAQ8Mknn5w9e9bYd4TD4VaHVl1dvXPnzs2bNxNdSIcmFouPHj26aNEiI7WPPUmHtmbNmmXLlhFdRUfHYrHUavWNGzeM1D72JB3U1atXR44cSXQV5qS0tNTT07PpzcBeHvYkHY5Wq502bZqbmxvRhZgZ3UcaAwcOFAqFhm0Ze5KORSgUKpXKuro6f/823bIQNbV79+6lS5casEEMSQdy5MiRnj179urVi+hCOoOUlJTevXsbpCkcbnUUxcXFXC4XE2IoBw4cqKysNEhT2JN0CAUFBba2tp3yghACXblyJSYm5uXbwZ6EeOPGjXNzc8OEGFxMTExiYqJAIHjJdrAnIdj9+/d9fHzYbDbRhXRa8fHxu3fvfpnTeTAkhFGpVPfu3Rs8eDDRhXR+uq9QXnh3HG4RQygUjhkzBhNiGk5OTg8fPnzh3TEkBNBoNHV1dVevXiW6kK6CTqdXVlZu2LDhxXbH4ZapabXas2fPTpw4kehCupzCwkIrK6sXOPzDnsTU4uLiIiMjia6iK/L39yeTyWq1ur07YkhMqr6+/uzZs66urkQX0kVxudz58+e3dy8cbplOYWEhiUTy8/MjupAu7caNG9bW1v369Wv7LhgSE8nLy1u/fv2xY8eILgS1Gw63TOTp06f79+8nugoEui9wjx492vbtsSdBXdGUKVO2b9/u6+vblo0xJKYQGxt77tw5QqboRM1SKBRyudza2rotG+Nwy+jOnj07b948TEiHQqVS5XJ5Gz8Oxp4EdVGHDx+uqqpasWKF3i2xJzEuoVBYUFBAdBWoGdOnT+dwOG3ZEnsS49q4cWO/fv3i4+OJLgS9OOxJjIvFYpl4CnTUdpWVlYmJiXo3w54EdWlRUVG3b99u/WMVDIkRFRYW1tbW9unTh+hCUIsuXbrk7+/frVu3VrbBzyWN6PTp02w2G0PSkY0ePVrvNnhMYkR+fn6DBg0iugrUGrFY/Msvv7S+DQ63UFcXFxf3008/tTKvLPYkRnTu3DmJREJ0FUiP9evXt34nIOxJjGjcuHEHDx7E6YLMHYbE8EaNGkUmk0kkkkQiodPpFhYWJBKJzWbrHfsiQnA4nH/++WfJkiUtbYDDLcOrrq6uqqri8/n19fUCgaCqqqq2trbr3HDd7Dg5OR0+fLiVDTAkhhcVFaXRaBov8fb2njx5MnEVodYwGIxvv/1WJpO1tAGGxPDmzJljb2/f8COVSp08eTKeKt+RRURE0On0ltZiSAwvKioqKCio4WDPy8trypQpRBeFWnPixIlWbrmIITGKefPm2draAgCNRps2bRqZTCa6ItQauVyenJzc0loMiVFERkZ2795dq9V6eHhgN9LxxcbGjh8/vqW1+gfKWgCZWlWjlBu6sE5uwrzZWdzy2FkzKuT1RNdiZhgUij2FZspndHBwcHBwaGmtnu9J/qksPllewJXXW1OoxikPoecxyZQ6lSKW7fOmT6hpnrGurm7nzp3r1q1rdm1rIfmVk50hEkQ7edhbmjTWCIlUiie1VWKValPIABM8nVar7d+/f0u3Z2gxJL+UZOVLauPYbZqYCCFjuF/DrVbINoWYYn7xu3fvRkRENPtJffMH7iVScXZdDSYEEWuAPZtiQU4SGOYmuq2Liopq6bus5kNSJKlVaTXNrkLIlCxJpJy6GhM80fbt21ua16b5kHDlUg86y8hVIaSfG50pVLZ4wogBcTicioqKZlc137/I1SqZpt33OkHI4FQarVCpNMETrVixoqVZT/GEIoQAAFqZPBu/cUcIAOCvv/66cuVKs6uwJ0EIAIDP5wuFwmZXYUgQAgCIj49/7iqgBhgShAAAPD09W1qFxyQIAQAkJiaeOnWq2VUYEoRAN3l2VlZWs6twuIUQAMDgwYPDw8ObXYUhQQgAwNXV1dXVtdlVONxCCAAgOTm5pYmFMCQIge57kpaOSbpuSIRV/PdeHf79+pVEF9LRiWuFD29earwk9d7tRTH9L/3V2oRuZiciImLu3LnNruq6xyTVvMpqbvNnfaIG1dzyVdNi3Xz9I4b99z4enLxsqaSuMDON0NIMzMnJycnJqdlVXTckAaFhq3f85OTqTnQhHZpKoVQqn59xffT02Y5unj0joggqyiiePHny6NGj+fPnN11lsJBcOXH0wrGD1Tyuowt7aNyUiXPfAoBFMf2lkrpfEtJ113z9/t2X548enL9648jJM3d8tLw4J3PI+Em3/j5ZL6nz8A0YOWVW8s0reanJANAvetTr73xMZzJ1jQT37sdkWack3aKQLbqF9ekfPer62b9K8rJZtnaxM+bEznjWSx7f/U3ihbO1NVVWNra9oobOeudDazt7ANjx0fLkW1dHTXk9M/kut6yke+/+kxYs+3TJGwDgHdh966+nr548dvDrjc+9Ike2287T1wGgVlB9fPc3j29flUnqPfwD42YvihoZ25b35OHNKxeOHnyal2VBtuzWI2z60vd9g0IBICXp5on9u0rzc6kMRtiAwa+9s9rRxU1XZ156StwbC6+ePCqs5rv7+s9cuqpH/4FSieTdCcOk9eIdJ644u3sCAL+8dOWUGGt7h+9OX7ek0u5evfj3ob3lxQV0FqvP4OEzl31gY+/Q7Av/+LufM5PvHfthW2lRHpNl3bP/wDc/3ESlM+5euXBi/3f8inJLimW3sF4zl6/yCQyp5lV8MH0MAJTkZb8xsDsA7DxzPeGf03/t2wkAY6bPmb1yDQDUi0XHd3/z4MZlaV0d29M79rV50fFTAaA4N3Pd3MmxM+dWlBTlpaZQ6fSIYSNnLlut+7V2NFVVVcY9Jkl/kPTLtk21gqreA4fSmaxqbnlb9qrmVvzz2/7QiAFu3r4Fman7Pv04N+1R36ExVAbz+uk/Tu7f1bBlSuKNjId3BgwfTaZQHyVc2/vpJ1KJeMDwMeLamsPffv7o9nXdZpJaobWdfVB4X9BoEs6f2rdlTeOnu3ziiL0zu++QkSMnz2TZ2oc2+kNo4+Dg172H7p9vcA/dwimL3tGNyDctnnnr3Akmy8YvNKysMO/7dSuunTmu99VdPH7o24/fzk195Orl5+zqnnr3dp2wBgAe3ry0fdWSp7lZgeF9bOwd7l45/+mSN+rFIt1eIkH1se+/9g0ODY8cUpydue2Dt3jlHIaV1StjJwLA7YtndZtdP/MHAIx4dYYllXbx+KHv160oLynyDw1jMKxunTvx6dLXpY3ui9L4hdeLRdtXLynMSgvpO8Ddx784O5NKZwCASqlQq1RBYb2t7e3T7iV+uWKhQial0Ri9Bw0DACbLJipmbFTMWBqN4ert59UtuKFxlVL5xbsLrp48ZmlJDezVj1teun/ruovHD/33fTh2iFtaEjkylkanXzlx9Mh3X7Tl/4bp9erVq9luxGA9CacgFwAGDI9dvG4rAMjq2zrT1NxV66MnTFPIZW/HDa0Xi1Zt2xMQGl5WXPDRa+OTb1+b9e5HDVuu3/O7q6d3fsaTjQtn2NjZb9h7lM5k+oeE/bJt0+Pb1/u+MhwA5n+0iUQi6QpYPWNsSuKNeomYafXsEsuomLFvf7qjocHZK9Z88sYE3eP+0aP7Rz8bc58/erA4J6P34Oih4ycDwKmDP/LKOCMmzZi/eiOJROIU5K6bN/mP3TuGxU1tZV5GYRX/+A/bSSTSRzsP9Ow/CADKigs8fAMA4Mh3X2m12uUbv46KGadWq7eveiv17u2rJ4/Hz1mk23f+hxuHT5ze0PEm/Xvu1flLY6bOunziSML5U5PeXKZSqW6dP0WmUGImvVZbXXX8h+10ptWnP//l5uOn1Wp3b/ow6d+/b/z959iZ85q+8OLcTLlU6uLutXr7vsa/qcGxE3Q5BIAdH72dfOtK5qP7vQcNm71iTUrSTSc394YWokbGimqqft3+me7HO5fPFWal+QSFbtj66tc9AAAVnUlEQVR7hEpn5KY+2vzWrJP7fxg5aaZuA7aXz5ZfTtIYTJFQ8N6E6ITzp+at3tABp7Q0+jFJWOQrZArl9sUzVDpt7Gtvsj282lqZmwcAUGl0W0fHerHIzskZANx9/AGgtpr/P1u6ugOAE9sdAOhWLF2X7e7jBwA1VTzdNkVZGWcO7SnOzhDV1mg1aq1WW11ZzgwI0q2Nihmrtx5OQe6fu3cwrW0XfLRZt+RRwjXdf6aju77SLWFYscS1Ql5piZuPX0vtpN5PVCoV4VGv6BICALqEcDlP+eWlNnb2kSPHAgCZTB4yblLq3dvZTx7Ew7OQ6AZUAOAX0hMAeGUc3e6hEQMzH97JfZIsEgqEVfyoUePtnV1unT+tVCrsnF10fQsASCViAChodFTd+IV7+Aa4uHvxyjlfv79owty3gntF6JbXVHHPHtqXdj9RwOOSSAAAvHKO3rcLANLuJwHAsPgpuh4pKLyvm49fxdOikvxcMoUMADb2jjQGEwBs7Byc3D0qnhbV8CudXD3a0rgppaampqSkzJkzp+kqw4TE06/bh9/8dHDbpisnjl47/cfkBW+/On/pC7em6w3adHch3e9TqwWA3NRHW5bP0Wq1YZGDHdlujxKuCav4cpm0YVs6U89V+0qlYvemD5VKxaK1W+ydXXQLa6r4AJD079/PbUyltzYXWW0VHwBcPLyfWy6qrQEAG0dn3WsEAN1Rk6S2tmkjllQqAKhUzy5eHT11VubDOwkXzgh4FQAQO2NOwxPxy0vPHz34P+XR/jtHeuMXbkmlfbLr4P7P//PkTsKTOwn9hsYs37xNqZBveHNGTRXXPySsR9/Igqz0p7mZ8noptEGdUAAA9k7ODUus7RwqnhaJRUJbB8cmr4gGAGqlqi0tmxifz09PT292lcEO3Hv0H/jl7/8knD/1y7ZP/9q3s9fAIX7de5IsLABAa5KJV66dPqZWqea8v3b0tNkAUMkpEVbx23Ufr7/2fVeSlx0xbNSgMfENC5kslkgg/+roeXdf/7Y3xbS2AYAaPu+55Ta29gAgqqluWFLD5wMAy86+SRvP6/PKCEe2253L5+RSqX9IWLcevQCAybIGgKiYcW9/+k0ba3N29/xk189Zjx/s/fTj5FtXrp48xmCxaqq4EcNGrfhiFwCcPrj7aW5m47eupQstdJEAAJFA0LBEyOc1vFIz0qtXL6OfllJZWkImk6Pjp4YNGAQA3NISALB1cACAoqx0ABAJBWkPkgz1dE1JJfUA4OTmCQBSiaQ0PxsANOq2/tHKTnlw/sgBazu7+R/+z8dcIX36645MdJ+EqpTKgjZ8P9C9TwQApCTdyE17rFtSlJOhkMtcPL0dXdxEgurkW1d1fZfuM4Ae/fR/nEomk0dMmimrr9dqtWOmz372RH37A0BywrWGqopyMuTS1o4JuWUc3esaPe0NAKjgFMnqJQDg8v/DvLy0RwCg0ah1I1sAqK6sUMikuoKfay207wAASDh/SqmQA8DjxBu8co61nV3jg3uz4OTk1KNHj2ZXGaYnqSwt+XBGbEDP3jZ29ql3EyhUWkBoOACE9R9c8bToq5ULvQKCOQW5ul+GkXTvHZF868pPW9d27xVRmJ0uEtYAQMXTooZhdyukkro9mz/W/e3c9sFi3UIqjb5+z5FJby5PSbp559K5zOS7Lu5eXE4xiUzeceJK4/FMUx6+AUPjptw6d+KzJa97+AeSSKTSgtx5qzeMeHXGtCUr9mz+aNe6Fd169q6qLK+qKGN7ekdPmNaW1zh8wrTTB35g2tjoDml0TzRk7KsJF05vWjTDOzBEpVKWF+W/9s6HDUftz9FoNF+8O9/Skurh1y075T4AhPaNZHt4A8Clvw5zy0oEvMqi7AwAqCgpBABbB0cXDy9eGWf1jHEMa+vY6bOfK3XQmPgLx3/Nz3iyeuY4J1f3/PQUAJi6eCXF0rItr6jjSEtLS0lJmT17dtNVhulJ1Cplj/4Dn+Zmpj9I8g0KXbVtt+7oc8ridwaNiSdTLMuKCyOGjYxs29cLL2bUtDfGvjbPwsLiyd1bvkGh73/1o5WNbU5KizedaOzq6T+qKsoAoE4oLMrO0P0rzs0EAE//wPV7jvQeNEwhlRVmpdGZrMFjJmhbHn40WPDx5hlLP3D28CovLqjmVnTvG+npHwgAr4yd+PanOzx8u+Wnp9SLxYPGxK/98TeGlVVb6rSxd4iMiR05aWbj/4IL126ZtmSFs7tnSX52dUV5974DfLp1b6kFuVQa0jeytqb6ceJ1Kxu7Oe+vjYoZ5xfSc9HaLY5st9Q7CUAird7xk7uPf2FWuq7fWL75G5+g0Nqaqho+l9VkEEWl0dfs+mXIuEmyekl+egrby3fx+i9GTprRlpfTofB4vLS05scIzc8F/FtJdqlMMtypw30EgbqaDJGgRCo2wbTZXC63oqKid+/eTVd13dNSXlJu2uNTB75vae281Rvb/jk46gjYbDabzW52FYbkBYkEVWn3EltaK5XUmbYc9LJSU1MzMzNnzpzZdBWG5AVFDBt1+E420VUggyktLc3IyGh2FYYEIQCAPn36tDTTKYYEIQAANzc3Nze3Zld13SsTEWrs7t27p0+fbnYV9iQIAQAUFRWVlZU1uwpDghAAwKBBg5Qt3AgFQ4IQAICPj09Lq/CYBCEAgEuXLt2+fbvZVRgShAAAHj161L57JiLU1cTGxuKUQgi1ptlTG3WaH24xKZY0iw53qT7qgiwtLByprV0pbSiHDh0qLi5udlXzIWHTmGVSsZGrQki/MqnYgdra9W2GcvHiRYXi+esudZoPSZC1HZmEx/SIeCqttru1gwmeaPHixd7ez0/codN8ElyojCgH9l9lBUYuDKHWXOOXMsiUCDvnNmz7soYPH06nN99ltdhdTHYPGM32/r00lyMVK9pwtSpChqIBKJWKr/BLHaj0VYF9TPCMUql0/fr1La1t7dOt0S5eDlTaibL8dJEA2jM3D9JRqdVkMplEdBlmx4HKYFlajnf1Hcdu8VtwwyorK8vLy2tpbfPXuDclbfPcPKjBq6++euDAAUfH5+doQ62jkSkmPiAWCARlZWVhYWHNrm3r9yQMMn6j0n4KJd2CjG9dx+fg4ODg0OLHA/gRFkJw/vz5lk7cwpAYl7+/f8Ocv6gju3TpUivHHTgSMKLCwsJ2TUaMiDJ16tQ+fVr8GA1DYkQhISHYk5iFV155pZW1ONwyouLi4vo2388IEaW4uPj771ucZxBDYlw9evRo6XQg1HEkJSXJ5fJWNsDhlhHV1dVVVlYGBAQQXQhqzeDBg21tbVvZAENiRB4eHtXV1W3YEBGplavbdXC4ZURubm5FRUVEV4FaU1ZWtmTJkta3wZAYUVBQUCtnBKGOICEhQe94GIdbRhQYGEih4DvcoY0fP55G03PlI/YkRuTo6FhZWYmdSUdmbW1NpVJb3wZDYlwDBw68c+cO0VWg5p07d+7zzz/XuxmGxLiio6Pz8/OJrgI178aNG3FxcXo3a+v1JOiFTZ06ddu2bS3d+wJ1fNiTGN2kSZNOnjxJdBXoecXFxVwuty1bYkiM7rXXXrt37x7RVaD/IRaL586d29KdRJ+Dwy1T+PXXX2tqat577z2iC0HP3Llzh8FgtDJrY2MYEhOJiYn5888/7e3tiS4EtRsOt0xk3bp1P/74I9FVIACA/fv3Jycnt317DImJREdHAwAewRPu7t27aWlp/fr1a/suONwyqbi4uP3797u6uhJdCGoH7ElM6sCBA+vWrSO6iq7r8ePHpaWl7d0LQ2JSbDZ71apVr7/+OtGFdEUnTpy4cOGCp6dne3fE4RYBkpKSDh06tHfvXqIL6UJkMhmHwwkMDHyBfTEkxKioqNiwYcO+ffuILqSruH///oABA15sXxxuEcPNzW3evHmzZs0iupAuISYmJigo6IV3x56ESDk5Oe++++7p06cZDAbRtXRaWVlZfn5+Ld17pC2wJyFScHDwkSNH4uLi2vXdFmq7kydPhoSEvExCMCTEc3Jyunr16t69ew8fPkx0LZ1NXFzc8OHDX74dHG51FDt27CCRSCtWrCC6kM5AKpUyGAw+n+/sbIBbyWFP0lGsXLkyPDx85MiRmZmZRNdi3h4/fnzkyBEAMEhCsCfpcIRC4TvvvBMdHb1gwQKiazFXy5cv/+GHHwzYIIakI/rxxx+LiopWr17t4uJCdC3m5GW+DGkFDrc6omXLls2ZM2fu3LlHjx4luhbzIJVKR48e7ebmZozGsSfp0LZt21ZZWfnBBx8Y6dffOUil0vz8fHd3dyPdwxVD0tGlpqauWbNm4sSJixYtIrqWDkcikSxbtmz37t1MJtN4z4LDrY4uPDz83LlzarV64sSJqampRJfTsZw6dWr16tVGTQj2JOaktLR03759Wq123bp1eqev7dyysrIOHjz41VdfmebpsCcxG56enps3bx44cODw4cPPnj1LdDmEUalUW7ZsWb58ucmeEUNiZsaNG5eUlMTj8aZOnfrw4cPn1o4ePZqgugxvzJgxzy05ffr0gwcPSCTS4cOH9d55x4AwJGZp4cKF27Zt279//5dffikUCnULJ06cWF1d/c477xBd3cuSSqUTJ06sqqpqWKLRaNLT09PS0iIiIshksonrwZCYK19f3z179kRGRk6dOvWnn37SXchFIpFSU1P//PNPoqt7KVu3bi0rKyORSDExMUqlcsOGDQqFws/Pb/369YTc8htDYt6io6OvXLmiVqsjIiI0Go3uU9Hffvut8Z9h85KYmHj79m3dY4FAsGnTpv79+9PpdCsrK6JKwk+3Ool+/fo1/JXVaDTDhg3bsWMH0UW9iEmTJnE4nIYfGQxGQkICoRVhT9IpjB07tvE4xMLCIjk5+fz584QW9SI+//zzsrKyxkukUumkSZOIqwgwJJ0En89vGBFoNBqtVisWi/fs2SOVSokurR2Sk5N1Q0etVqvVanUvRKvVNu5YCIG3vewMVq9ezePx6urqJBJJfX29QCCQy+UyheKWiJ/C4Q90dCsQ196uLi+XShyp9NFsb4FS/m/lU8IfX+FxAqxsY9netSpFhVQyKtDX0dHR1dWVSqXa2dlZW1szmUwWi0X4qdB4TNIJPRDyFBr1ZR7nQQ1XodHoxmEaIFnAs9+1FkikjvCYpP3/n0ALwKJYxjh7+TCtg63tA61sjfb2tBuGpFPRALydcqNMJpGqVUTX8uLsLGlTPAJmeLzIRHLGgCHpJDQAv3NybvDLSqR1RNdiGOE2joMd3Sa5BxBdCB6TdBZbsh8kC/n1aiXRhRhMqqj6qVTMIFNi2aY7A6VZ+OlWZ3CFz7lTU9mZEqJTq5TvK84orhcRWwaGxOyliap3FaSqNBqiCzEKsUq5PvNenlhIYA14TGLe/ijLO16aX6dSEF2IcTlS6eu7Dwi1JuaOk9iTmLE6lTJJUNnpEwIA1QrZdX67b75jKBgSMyZQyLJFAqKrMJGbVWUKjZqQp8aQmKun9XVrMu50zgOR5giV8qn3LxLy1BgSc3W4NJen6LinZj1Z++WDt9cauFEtXOaVGLjNNsCQmCtXGpOA64/aTJRbwPLzMmybMo3Kk2Ft2DbbAkNirp4I+USX0CJlnURWwWP5Gf5LwMs8julHmPiNu1n6q7ygoL7WeO1XXr719M+/xQVPyQwGe/jA4PcWWlAoxUdOVlxOCHl/ce4Pv9TlFdGcHLq/v9gpqq9uF97t+8W/najLL6I5OXiMjwEAlr+3wQu7LSiPdvYItzHKTI0twZ7ELOWKaxRG+/Ywf9/htE3fMNzYIauXeU8bX3r639Iz/wKAWiYXFxRnfPG966ihQe++qayry/72J90upWf+ffLxVjKDFrJqifOQyPx9hwHAytDDLQAALfDlpj4Sw57ELE1173aDX9aGDdtN8Di96Ne/vKfHB7+7AAC0Gk3x4ZNyXjUAqOqlFCYj4vstNAc7AKjLKSg/fxUApBW8nJ0HXIZGhW/5SHeBpLjgqbjwKdXWxuDlKTTqkc7tvhH7S8KQmCWJ0U7T4pz4B0gkl6FRihqhlFtVcvysWiZ3HhoJAJJijpW/ty4hAKCWyixtrAGg7O/LGpUqcNnchkuIVWIJy8/wYy0AqFerOFKxF4NljMZbgiExS/uKMozUsigrn0ynPXxnHWi1AMD0cu/12Ud2PYIBQFxU4hTZt2FLCaec6e0BAMK0LLqLE9Pz2bz3Wq1W8rRUd1hicCSAW1Vlr3sFG6PxlmBIzJIrnZkvqTXGR8BalcplaGTg0rlSLp9mb0d3dSZZWACASlIv51Vb/X//oNVoJMUc97EjAEBRI6Q5/vesqrrcQnW91BhH7QDAolj6Mg0/imsdHribpU+CIoz0JQmd7VyXV0R1sLPrEcxwZ+sSoutGAIDl++x4QFrO1cgVVr5eAGBpayOt5GnVz84ZKT5yEgCsjBMSDzprsKOpb9WCITFX7gyjTNbmFhstLixJ+Xhr+flrxUdOFvx8TLdcUsQBgIaeRJcZK19PAHB5ZYCiuiZj63e8m3fTP9vJu3kHAFi+RvhoC8CGSpWZ/AwuHG6ZpXqNSqQwysm/nhPHKISi8gvXBA9TGW4u/vOm65aLi0ooLCu687MvKHSZ0SXBa1qcrLqm8tJN3q17zkMiXaIH1abnUKyMcs8QkUJBtzD1XMB4PYm5Wp2e+KTWXOcyfTFUC/KKgF4xLkbpo1qBITFXWq120r3z9S3PilJ9/3Hqf7Y1XW5BtdQomv8Euf+eLww4TMrb81vp6WbO26WwrFRiSbO7ROz6zDrQr6UGBzq4bgqJNFR5bYchMWMHnmYdL81taa1aLlcImjl1RaNUWlhaNrsLzdnBgmKwEbhSVKeStO/bcZqTfUu1UUgWy/zD4lx9DVRdO+AxiRnraeNwgUIVtXBlIplGY7gROfehpY217ttGg3Cg0oY6eRiqtXbBT7fMWKQ9e6FvKJ3c+f/SsWnML3sMsqE038kYG4bEvMWyfdYG9evIF5a8PDqZsjqwj4dpT0VpDENi9iIdXO0tO+3NeEkkUpS9a7itE5E14IF7J6AF2JR9776Aq+pcv01rimUs22eRbw9iy8CQdB4ZIsFHGUlETSlicNYU6o+9hrHpRvlSsl1wuNV59LBxeN0r2JnGoBBx900DsqVQnamMT7pHdISEYE/SCUnUyjqV8tv8lMy6Gpm53YDBhkLtY+e8sltvZkf6yA5D0jlpAa5XlRZJRAwLyuNafoVMQrMg21vSBAqZQClzsKQ7UOkd4bFQpZCqVZ4MVpS9qxbAm8mKsCP4vlZNYUg6P6VWUyqVsCgUZyqDJ5fy5PUuNKYLrUM85sulCq3Wjc6wgI47RMSQIKQHHrgjpAeGBCE9MCQI6YEhQUgPDAlCemBIENLj/wC/EEu13bRf9wAAAABJRU5ErkJggg==",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Required imports for graph visualization\n",
        "from IPython.display import Image, display\n",
        "from dataclasses import dataclass\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class NodeStyles:\n",
        "    \"\"\"\n",
        "    A data class defining styles for graph nodes.\n",
        "    \"\"\"\n",
        "\n",
        "    # Style for default nodes\n",
        "    default: str = (\n",
        "        \"fill:#45C4B0, fill-opacity:0.3, color:#23260F, \"\n",
        "        \"stroke:#45C4B0, stroke-width:1px, font-weight:bold, line-height:1.2\"\n",
        "    )\n",
        "    # Style for first node (e.g., start node)\n",
        "    first: str = (\n",
        "        \"fill:#45C4B0, fill-opacity:0.1, color:#23260F, \"\n",
        "        \"stroke:#45C4B0, stroke-width:1px, font-weight:normal, \"\n",
        "        \"font-style:italic, stroke-dasharray:2,2\"\n",
        "    )\n",
        "    # Style for last node (e.g., end node)\n",
        "    last: str = (\n",
        "        \"fill:#45C4B0, fill-opacity:1, color:#000000, \"\n",
        "        \"stroke:#45C4B0, stroke-width:1px, font-weight:normal, \"\n",
        "        \"font-style:italic, stroke-dasharray:2,2\"\n",
        "    )\n",
        "\n",
        "\n",
        "# Display the workflow graph with the defined node styles\n",
        "display(\n",
        "    Image(\n",
        "        app.get_graph().draw_mermaid_png(\n",
        "            background_color=\"white\", node_colors=NodeStyles()\n",
        "        )\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Running Workflow\n",
        "\n",
        "You can interact with the application by sending messages. Once the conversation exceeds 6 messages, it automatically summarizes and shortens.\n",
        "\n",
        "- The `app.stream` method handles streaming of messages and triggers the nodes accordingly.\n",
        "- Check the internal state with `app.get_state(config)` to see how messages and summaries are updated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here is a helper function, `print_update`, which prints updates in real time during streaming."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_update(update):\n",
        "    \"\"\"\n",
        "    Helper function to print out updates during streaming.\n",
        "    \"\"\"\n",
        "    for k, v in update.items():\n",
        "        for m in v.get(\"messages\", []):\n",
        "            m.pretty_print()\n",
        "        if \"summary\" in v:\n",
        "            print(v[\"summary\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below is a single code cell demonstrating how we handle user messages and process them through streaming mode. We import `HumanMessage`, configure the session with a thread ID, and send three user messages in sequence. After each message, the updates are streamed and printed in real time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Hello! Nice to meet you. My name is Junseong.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Hello, Junseong! Nice to meet you too! How can I assist you today?\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Do you remember my name?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Yes, your name is Junseong! How can I help you today?\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "I am working as an AI researcher.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "That's great to hear, Junseong! AI research is a fascinating field with so many exciting developments. What specific area of AI are you focusing on?\n"
          ]
        }
      ],
      "source": [
        "# Initialize a configuration object with thread ID\n",
        "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "\n",
        "# 1) First user message\n",
        "input_message = HumanMessage(content=\"Hello! Nice to meet you. My name is Junseong.\")\n",
        "input_message.pretty_print()\n",
        "\n",
        "# Process the first message in streaming mode and print updates\n",
        "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"updates\"):\n",
        "    print_update(event)\n",
        "\n",
        "# 2) Second user message\n",
        "input_message = HumanMessage(content=\"Do you remember my name?\")\n",
        "input_message.pretty_print()\n",
        "\n",
        "# Process the second message in streaming mode and print updates\n",
        "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"updates\"):\n",
        "    print_update(event)\n",
        "\n",
        "# 3) Third user message\n",
        "input_message = HumanMessage(content=\"I am working as an AI researcher.\")\n",
        "input_message.pretty_print()\n",
        "\n",
        "# Process the third message in streaming mode and print updates\n",
        "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"updates\"):\n",
        "    print_update(event)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So far, no summary has been generated because there are only six messages. Once the conversation exceeds six messages, summarization will be triggered."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='Hello! Nice to meet you. My name is Junseong.', additional_kwargs={}, response_metadata={}, id='82e87de6-b2bb-43f6-8f5a-98c74569d7ca'),\n",
              "  AIMessage(content='Hello, Junseong! Nice to meet you too! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 21, 'total_tokens': 41, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None}, id='run-e7977301-95d5-461f-8c51-373646cb7ab6-0', usage_metadata={'input_tokens': 21, 'output_tokens': 20, 'total_tokens': 41, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              "  HumanMessage(content='Do you remember my name?', additional_kwargs={}, response_metadata={}, id='1f12ef85-6054-48bc-b6db-e61bd7af74b8'),\n",
              "  AIMessage(content='Yes, your name is Junseong! How can I help you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 54, 'total_tokens': 71, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None}, id='run-5d1013ff-1fb5-407e-a160-8163b41fb927-0', usage_metadata={'input_tokens': 54, 'output_tokens': 17, 'total_tokens': 71, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              "  HumanMessage(content='I am working as an AI researcher.', additional_kwargs={}, response_metadata={}, id='cbc9c016-79af-4c3a-8240-62951fd41b30'),\n",
              "  AIMessage(content=\"That's great to hear, Junseong! AI research is a fascinating field with so many exciting developments. What specific area of AI are you focusing on?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 86, 'total_tokens': 118, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None}, id='run-f5a63532-897a-4400-b6e6-2e41f2a01613-0', usage_metadata={'input_tokens': 86, 'output_tokens': 32, 'total_tokens': 118, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "values = app.get_state(config).values\n",
        "values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can see that there are only six messages in the list, which is why no summary has been created yet. Let's send another message to exceed that threshold."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "I'm recently learning more about LLMs. I'm reading the latest papers on LLM.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "That's an exciting area to explore! Large Language Models (LLMs) have made significant advancements and have a wide range of applications. Are there any specific papers or topics within LLMs that you're particularly interested in or have found intriguing?\n",
            "================================\u001b[1m Remove Message \u001b[0m================================\n",
            "\n",
            "\n",
            "================================\u001b[1m Remove Message \u001b[0m================================\n",
            "\n",
            "\n",
            "================================\u001b[1m Remove Message \u001b[0m================================\n",
            "\n",
            "\n",
            "================================\u001b[1m Remove Message \u001b[0m================================\n",
            "\n",
            "\n",
            "================================\u001b[1m Remove Message \u001b[0m================================\n",
            "\n",
            "\n",
            "================================\u001b[1m Remove Message \u001b[0m================================\n",
            "\n",
            "\n",
            "Sure! So far, you've introduced yourself as Junseong, an AI researcher who is currently learning about Large Language Models (LLMs) and reading the latest papers on the topic. If there's anything specific you would like to discuss or inquire about regarding LLMs or AI research, feel free to let me know!\n"
          ]
        }
      ],
      "source": [
        "# Create a new user message\n",
        "input_message = HumanMessage(\n",
        "    content=\"I'm recently learning more about LLMs. I'm reading the latest papers on LLM.\"\n",
        ")\n",
        "\n",
        "# Display the message content\n",
        "input_message.pretty_print()\n",
        "\n",
        "# Process and print updates in streaming mode\n",
        "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"updates\"):\n",
        "    print_update(event)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Because the conversation now has more than six messages, summarization will be triggered.\n",
        "\n",
        "During this process, old messages are removed, and only the summary plus the last two messages remain in the conversation state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content=\"I'm recently learning more about LLMs. I'm reading the latest papers on LLM.\", additional_kwargs={}, response_metadata={}, id='7ba54cd3-47b7-4da9-8867-69aa41cb8914'),\n",
              "  AIMessage(content=\"That's an exciting area to explore! Large Language Models (LLMs) have made significant advancements and have a wide range of applications. Are there any specific papers or topics within LLMs that you're particularly interested in or have found intriguing?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 48, 'prompt_tokens': 143, 'total_tokens': 191, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None}, id='run-349e654d-3a5c-4b0b-acef-c2c604d6ef40-0', usage_metadata={'input_tokens': 143, 'output_tokens': 48, 'total_tokens': 191, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
              " 'summary': \"Sure! So far, you've introduced yourself as Junseong, an AI researcher who is currently learning about Large Language Models (LLMs) and reading the latest papers on the topic. If there's anything specific you would like to discuss or inquire about regarding LLMs or AI research, feel free to let me know!\"}"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check the conversation state again to see the new summary\n",
        "values = app.get_state(config).values\n",
        "values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As you can see, the summary has been added, and the older messages have been replaced by `RemoveMessage` actions. Only the most recent messages and the newly created summary remain.\n",
        "\n",
        "You can now continue the conversation, and despite only having the last two messages visible, the system still retains the overall context through the summary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Do you remember my name?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Yes, your name is Junseong. How can I assist you further today?\n"
          ]
        }
      ],
      "source": [
        "# Create a user message asking if the assistant remembers the user's name\n",
        "input_message = HumanMessage(content=\"Do you remember my name?\")\n",
        "input_message.pretty_print()\n",
        "\n",
        "# Process in streaming mode\n",
        "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"updates\"):\n",
        "    print_update(event)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Even though the older messages were removed from the conversation history, the summary contains the essential context. The model can respond accurately based on the stored summary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Do you also recall my occupation?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Yes, you mentioned that you are an AI researcher currently learning about Large Language Models (LLMs). If you have any questions or topics you want to discuss, feel free to share!\n"
          ]
        }
      ],
      "source": [
        "# Create another user message asking about the user's occupation\n",
        "input_message = HumanMessage(content=\"Do you also recall my occupation?\")\n",
        "input_message.pretty_print()\n",
        "\n",
        "# Process in streaming mode\n",
        "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"updates\"):\n",
        "    print_update(event)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "langchain-opentutorial-QDzDRI-1-py3.11",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
