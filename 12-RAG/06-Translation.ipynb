{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation\n",
    "\n",
    "- Author: [Wonyoung Lee](https://github.com/BaBetterB)\n",
    "- Peer Review: \n",
    "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/BaBetterB/LangChain-OpenTutorial/blob/main/15-Agent/05-Iteration-HumanInTheLoop.ipynb)\n",
    "[![Open in GitHub](https://img.shields.io/badge/Open%20in%20GitHub-181717?style=flat-square&logo=github&logoColor=white)](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/07-TextSplitter/04-SemanticChunker.ipynb)\n",
    "\n",
    "\n",
    "## Overview\n",
    "\n",
    "This tutorial compares two approaches to translating Chinese text into English using LangChain.\n",
    "\n",
    "The first approach utilizes a single LLM (e.g. GPT-4) to generate a straightforward translation. The second approach employs Retrieval-Augmented Generation (RAG), which enhances translation accuracy by retrieving relevant documents.\n",
    "\n",
    "The tutorial evaluates the translation accuracy and performance of each method, helping users choose the most suitable approach for their needs.\n",
    "\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "- [Overview](#overview)\n",
    "- [Environement Setup](#environment-setup)\n",
    "- [Translation using LLM](#translation-using-llm)\n",
    "- [Translation using RAG](#translation-using-rag)\n",
    "- [Evaluation of translation results](#evaluation-of-translation-resultsr)\n",
    "\n",
    "\n",
    "### References\n",
    "\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
    "\n",
    "**[Note]**\n",
    "- `langchain-opentutorial` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials. \n",
    "- You can checkout the [ `langchain-opentutorial` ](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load sample text and output the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install langchain-opentutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "from langchain_opentutorial import package\n",
    "\n",
    "\n",
    "package.install(\n",
    "    [\n",
    "        \"langsmith\",\n",
    "        \"langchain\",\n",
    "        \"langchain_core\",\n",
    "        \"langchain_community\",\n",
    "        \"load_dotenv\",\n",
    "        \"langchain_openai\",\n",
    "        \"transformers\",\n",
    "        \"faiss-cpu\",\n",
    "        \"sentence_transformers\",\n",
    "        \"sacrebleu\",\n",
    "        \"unbabel-comet\",\n",
    "        \"load_from_checkpoint\",\n",
    "    ],\n",
    "    verbose=False,\n",
    "    upgrade=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables have been set successfully.\n"
     ]
    }
   ],
   "source": [
    "# Set environment variables\n",
    "from langchain_opentutorial import set_env\n",
    "\n",
    "set_env(\n",
    "    {\n",
    "        \"OPENAI_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
    "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
    "        \"LANGCHAIN_PROJECT\": \"Translation\",  # title\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can alternatively set `OPENAI_API_KEY` in `.env` file and load it.\n",
    "\n",
    "[Note] This is not necessary if you've already set `OPENAI_API_KEY` in previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuration File for Managing API Keys as Environment Variables\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API Key Information\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation using LLM\n",
    "\n",
    "Translation using LLM refers to using a large language model (LLM), such as GPT-4, to translate text from one language to another. \n",
    "The model processes the input text and generates a direct translation based on its pre-trained knowledge. This approach is simple, fast, and effective.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chinese_text: äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜ä¸–ç•Œï¼Œå„å›½éƒ½åœ¨åŠ ç´§ç ”ç©¶å¦‚ä½•åˆ©ç”¨è¿™ä¸€æŠ€æœ¯æé«˜ç”Ÿäº§åŠ›ã€‚\n",
      "Translation: Artificial intelligence is transforming the world, and countries are intensifying their research on how to leverage this technology to enhance productivity.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableSequence\n",
    "\n",
    "# Create LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# Create PromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a professional translator.\",\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Please translate the following Chinese document into natural and accurate English.\"\n",
    "            \"Consider the context and vocabulary to ensure smooth and fluent sentences.:.\\n\\n\"\n",
    "            \"**Chinese Original Text:** {chinese_text}\\n\\n**English Translation:**\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "translation_chain = RunnableSequence(prompt, llm)\n",
    "\n",
    "chinese_text = \"äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜ä¸–ç•Œï¼Œå„å›½éƒ½åœ¨åŠ ç´§ç ”ç©¶å¦‚ä½•åˆ©ç”¨è¿™ä¸€æŠ€æœ¯æé«˜ç”Ÿäº§åŠ›ã€‚\"\n",
    "\n",
    "response = translation_chain.invoke({\"chinese_text\": chinese_text})\n",
    "\n",
    "print(\"Chinese_text:\", chinese_text)\n",
    "print(\"Translation:\", response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation using RAG \n",
    "\n",
    "Translation using RAG (Retrieval-Augmented Generation) enhances translation accuracy by combining a pre-trained LLM with a retrieval mechanism. It first retrieves relevant documents or data related to the input text, then uses this additional context to generate a more precise and contextually accurate translation. This approach is particularly useful for technical terms, specialized content, or context-sensitive translations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Search Implementation Using FAISS\n",
    "\n",
    "FAISS (Facebook AI Similarity Search) is a library developed by Facebook AI for efficient similarity search and clustering of dense vectors. It is widely used for approximate nearest neighbor (ANN) search in large-scale datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search result\n",
      "1. å½“åœ°çƒå‘˜å¹¶éä¸“ä¸šäººå£«ï¼Œè€Œæ˜¯å†œæ°‘ã€å»ºç­‘å·¥äººã€æ•™å¸ˆå’Œå­¦ç”Ÿï¼Œå¯¹è¶³çƒçš„çƒ­çˆ±å°†ä»–ä»¬å‡èšåœ¨ä¸€èµ·\n",
      "2. â€å¡å¡è¯´é“\n",
      "3. â€œè¶³çƒè®©æˆ‘ä»¬ç»“è¯†æ–°æœ‹å‹ï¼Œè¿æ¥æ›´å¹¿é˜”çš„ä¸–ç•Œ\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "file_path = \"data/news_cn.txt\"\n",
    "if not os.path.exists(file_path):\n",
    "    raise FileNotFoundError(f\"file not found!!: {file_path}\")\n",
    "\n",
    "loader = TextLoader(file_path, encoding=\"utf-8\")\n",
    "docs = loader.load()\n",
    "\n",
    "\n",
    "# Vectorizing Sentences Individually\n",
    "sentences = []\n",
    "for doc in docs:\n",
    "    text = doc.page_content\n",
    "    sentence_list = text.split(\"ã€‚\")  # Splitting Chinese sentences based on '.'\n",
    "    sentences.extend(\n",
    "        [sentence.strip() for sentence in sentence_list if sentence.strip()]\n",
    "    )\n",
    "\n",
    "\n",
    "# Store sentences in the FAISS vector database\n",
    "vector_store = FAISS.from_texts(sentences, embedding=embeddings)\n",
    "\n",
    "# Search vectors using keywords \"äººå·¥æ™ºèƒ½\"\n",
    "search_results = vector_store.similarity_search(\"äººå·¥æ™ºèƒ½\", k=3)\n",
    "\n",
    "# check result\n",
    "print(\"Search result\")\n",
    "for idx, result in enumerate(search_results, start=1):\n",
    "    print(f\"{idx}. {result.page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's compare translation using LLM and translation using RAG.\n",
    "\n",
    "First, write the necessary functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "\n",
    "# Document Search Function (Used in RAG)\n",
    "def retrieve_relevant_docs(query, vector_store, k=3):\n",
    "    # Perform search and return relevant documents\n",
    "    search_results = vector_store.similarity_search(query, k=k)\n",
    "    return [doc.page_content for doc in search_results]\n",
    "\n",
    "\n",
    "# Translation using only LLM\n",
    "def translate_with_llm(chinese_text):\n",
    "    prompt_template_llm = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"You are a translation expert. Translate the following Chinese sentence into English:\",\n",
    "            ),\n",
    "            (\"user\", f'Chinese sentence: \"{chinese_text}\"'),\n",
    "            (\"user\", \"Please provide an accurate translation.\"),\n",
    "        ]\n",
    "    )\n",
    "    # translation_chain_llm = LLMChain(prompt=prompt_template_llm, llm=llm)\n",
    "    translation_chain_llm = RunnableSequence(prompt_template_llm, llm)\n",
    "    return translation_chain_llm.invoke({\"chinese_text\": chinese_text})\n",
    "\n",
    "\n",
    "# RAG-based Translation\n",
    "def translate_with_rag(chinese_text, vector_store):\n",
    "    retrieved_docs = retrieve_relevant_docs(chinese_text, vector_store)\n",
    "\n",
    "    # Add retrieved documents as context\n",
    "    context = \"\\n\".join(retrieved_docs)\n",
    "\n",
    "    # Construct prompt template (Using RAG)\n",
    "    prompt_template_rag = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"You are a translation expert. Below is the Chinese text that needs to be translated into English. Additionally, the following context has been provided from relevant documents that might help you in producing a more accurate and context-aware translation.\",\n",
    "            ),\n",
    "            (\"system\", f\"Context (Relevant Documents):\\n{context}\"),\n",
    "            (\"user\", f'Chinese sentence: \"{chinese_text}\"'),\n",
    "            (\n",
    "                \"user\",\n",
    "                \"Please provide a translation that is both accurate and reflects the context from the documents provided.\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    translation_chain_rag = RunnableSequence(prompt_template_rag, llm)\n",
    "\n",
    "    # Request translation using RAG\n",
    "    return translation_chain_rag.invoke({\"chinese_text\": chinese_text})\n",
    "\n",
    "\n",
    "# Function to store document text as a list\n",
    "def chinese_text_from_file_loader(path):\n",
    "    # Load data\n",
    "    loader = TextLoader(path, encoding=\"utf-8\")\n",
    "    docs = loader.load()\n",
    "\n",
    "    # Retrieve the page_content of the first document from docs and embed it\n",
    "    text = docs[0].page_content\n",
    "\n",
    "    # Vectorize sentences individually\n",
    "    sentences = []\n",
    "    for doc in docs:\n",
    "\n",
    "        text = docs[0].page_content\n",
    "        sentence_list = text.split(\n",
    "            \"ã€‚\"\n",
    "        )  # In Chinese, sentences are usually separated by 'ã€‚'\n",
    "        sentences.extend(\n",
    "            [sentence.strip() for sentence in sentence_list if sentence.strip()]\n",
    "        )\n",
    "\n",
    "    print(len(sentences))\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use the written functions to perform the comparison.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "å½“å‰ï¼Œæˆ‘å›½ä¸­åŒ»è¯é¢†åŸŸé«˜æ°´å¹³ç§‘æŠ€åˆ›æ–°å¹³å°åŠ é€Ÿé›†èš2025å¹´1æœˆ9æ—¥åœ¨åŒ—äº¬ä¸¾è¡Œçš„å…¨å›½ä¸­åŒ»è¯ç§‘æŠ€å·¥ä½œä¼šè®®ä¸Šçš„æ•°æ®æ˜¾ç¤ºï¼Œæˆ‘å›½ä¸æ–­æ·±åŒ–ä¸­åŒ»è¯ç§‘æŠ€åˆ›æ–°ä½“ç³»å»ºè®¾ï¼Œä¸­åŒ»è¯ç§‘æŠ€åˆ›æ–°æˆæœæ¥è¿æ¶Œç°ç›®å‰ï¼Œå·²åŸºæœ¬æ„å»ºèµ·è¦†ç›–â€œå›½å®¶â€”è¡Œä¸šâ€”åœ°æ–¹â€ä¸‰çº§ä¸­åŒ»è¯ç§‘æŠ€åˆ›æ–°å¹³å°ä½“ç³»ï¼Œå„çœçº§å¹³å°å»ºè®¾æ•°é‡è¶…è¿‡1200ä¸ªä¸­åŒ»è¯é¢†åŸŸå·²æœ‰7ä¸ªå…¨å›½é‡ç‚¹å®éªŒå®¤ã€5ä¸ªå›½å®¶å·¥ç¨‹ç ”ç©¶ä¸­å¿ƒã€4ä¸ªå›½å®¶åŒ»å­¦æ”»å…³äº§æ•™èåˆåˆ›æ–°å¹³å°è·æ‰¹å»ºè®¾ï¼Œ46ä¸ªå›½å®¶ä¸­åŒ»è¯ä¼ æ‰¿åˆ›æ–°ä¸­å¿ƒå»ºè®¾æ­£åœ¨æ¨è¿›åœ°æ–¹ç ”ç©¶å¹³å°ã€ç§‘ç ”é™¢æ‰€å»ºè®¾åŠ›åº¦åŠ å¤§ï¼Œä¸­åŒ»è¯å¹¿ä¸œçœå®éªŒå®¤ã€æ¹–åŒ—æ—¶çå®éªŒå®¤ã€æ²³å—çœä¸­åŒ»è¯ç§‘å­¦é™¢ç­‰ä¸€æ‰¹çœçº§æ–°å‹ç§‘ç ”å¹³å°ç›¸ç»§ç»„å»ºæ®ä»‹ç»ï¼Œæˆ‘å›½å¯¹ä¸­åŒ»è¯åŸåˆ›ç†è®ºçš„ç§‘å­¦é˜é‡Šä¸è®¤è¯†è¿›ä¸€æ­¥æ·±åŒ–ï¼Œåœ¨ç ”ç©¶ä¸Šå–å¾—ä¸€æ‰¹é‡è¦æˆæœåœ¨å¿ƒè„‘è¡€ç®¡ã€ä»£è°¢ã€æ¶ˆåŒ–ç­‰å¤šä¸ªç–¾ç—…é¢†åŸŸï¼Œä¸­åŒ»ä¸´åºŠè¯„ä»·ç ”ç©¶å–å¾—é‡è¦è¿›å±•2023å¹´ä»¥æ¥ï¼ŒåŸºäºå¾ªè¯è¯æ®å’Œå¤§é‡ä¸´åºŠå®è·µï¼Œé´é€‰å‘å¸ƒäº†50ä¸ªä¸­åŒ»æ²»ç–—ä¼˜åŠ¿ç—…ç§ã€52ä¸ªä¸­è¥¿åŒ»ç»“åˆè¯Šç–—æ–¹æ¡ˆã€100é¡¹é€‚å®œæŠ€æœ¯ã€100ä¸ªç–—æ•ˆç‹¬ç‰¹çš„ä¸­è¯å“ç§ä¸­è¯èµ„æºä¿æŠ¤å’Œåˆ›æ–°ç ”å‘ä¹Ÿæœ‰ä¸å°‘æ–°è¿›å±•æ®ä»‹ç»ï¼Œæˆ‘å›½å»ºç«‹äº†28ä¸ªä¸­è¯æç§å­ç§è‹—ç¹è‚²åŸºåœ°ï¼Œ120å¤šç§å¤§å®—æˆ–é“åœ°è¯æå®ç°è§„èŒƒåŒ–ç§æ¤ï¼Œ100ä½™ç§ä¸­è¯æå¼€å±•ç”Ÿæ€ç§æ¤2021å¹´ä»¥æ¥ï¼Œ43ä¸ªä¸­è¯æ–°è¯è·æ‰¹ä¸Šå¸‚ï¼ŒåŒ…æ‹¬19ä¸ªå¤ä»£ç»å…¸åæ–¹ä¸­è¯å¤æ–¹åˆ¶å‰‚ï¼Œä¸­è¯æ–°è¯ç ”å‘è¿›ç¨‹æ˜æ˜¾åŠ å¿«\n",
      "\n",
      "LLM\n",
      "Currently, high-level technological innovation platforms in the field of traditional Chinese medicine (TCM) in our country are accelerating their gathering. Data from the National TCM Science and Technology Work Conference held on January 9, 2025, in Beijing shows that our country is continuously deepening the construction of the TCM technological innovation system, with TCM technological innovation achievements emerging in succession. At present, a three-tiered TCM technological innovation platform system covering \"national - industry - local\" has basically been established, with the number of provincial-level platform constructions exceeding 1,200. In the field of TCM, seven national key laboratories, five national engineering research centers, and four national medical innovation platforms integrating industry and education have been approved for construction, and the construction of 46 national TCM inheritance and innovation centers is underway. \n",
      "\n",
      "The construction of local research platforms and research institutes has increased, with a number of new provincial-level research platforms such as the Guangdong Provincial Laboratory of TCM, Hubei Shizhen Laboratory, and Henan Provincial Academy of TCM being established successively. It is reported that our country's scientific interpretation and understanding of the original theories of TCM have further deepened, achieving a number of important results in research across various disease fields including cardiovascular, metabolic, and digestive diseases. Significant progress has been made in clinical evaluation research of TCM. Since 2023, based on evidence and a large amount of clinical practice, 50 advantageous diseases treated by TCM, 52 integrated TCM and Western medicine treatment plans, 100 appropriate technologies, and 100 uniquely effective Chinese medicinal varieties have been selected and released. \n",
      "\n",
      "There have also been several new advancements in the protection and innovative research and development of Chinese medicinal resources. It is reported that our country has established 28 seed and seedling breeding bases for Chinese medicinal materials, with standardized planting achieved for over 120 varieties of commonly used or authentic medicinal materials, and ecological planting being conducted for over 100 varieties of Chinese medicinal materials. Since 2021, 43 new Chinese medicinal drugs have been approved for market release, including 19 ancient classic prescriptions and compound formulations, and the research and development process for new Chinese medicinal drugs has significantly accelerated.\n",
      "\n",
      "RAG\n",
      "Currently, high-level technological innovation platforms in the field of traditional Chinese medicine (TCM) in our country are accelerating their aggregation. Data from the National TCM Science and Technology Work Conference held on January 9, 2025, in Beijing shows that our country is continuously deepening the construction of the TCM technological innovation system, with a steady stream of innovative achievements emerging. We have basically established a three-tier TCM technological innovation platform system covering \"national - industry - local\" levels, with the number of provincial-level platforms exceeding 1,200.\n",
      "\n",
      "In the TCM field, seven national key laboratories, five national engineering research centers, and four national medicine innovation platforms integrating production and education have been approved for construction. Furthermore, the construction of 46 national TCM inheritance and innovation centers is underway. The strength of local research platforms and research institutions has been significantly increased, with several new provincial-level research platforms such as the Guangdong Provincial TCM Laboratory, Hubei Shizhen Laboratory, and the Henan Provincial Academy of Traditional Chinese Medicine being established one after another.\n",
      "\n",
      "It is reported that our country has deepened the scientific interpretation and understanding of original TCM theories, achieving a number of important results in research across various disease areas, including cardiovascular diseases, metabolic disorders, and digestive issues. Important progress has been made in clinical evaluation research of TCM. Since 2023, based on evidence from clinical practices, 50 advantageous disease categories for TCM treatment, 52 integrated TCM and Western medicine treatment plans, 100 appropriate technologies, and 100 uniquely effective TCM herbal varieties have been selected and published.\n",
      "\n",
      "There have also been significant advances in the protection and innovative research and development of TCM resources. Our country has established 28 seed breeding bases for medicinal materials, with standardized cultivation achieved for over 120 commonly used or authentic medicinal materials and ecological cultivation initiated for more than 100 types of medicinal herbs. Since 2021, 43 new TCM drugs have been approved for market launch, including 19 formulations of ancient classic prescriptions, with the pace of new TCM drug development significantly accelerated.\n"
     ]
    }
   ],
   "source": [
    "sentences = chinese_text_from_file_loader(\"data/comparison_cn.txt\")\n",
    "chinese_text = \"\"\n",
    "\n",
    "for sentence in sentences:\n",
    "    chinese_text += sentence\n",
    "\n",
    "# LLM\n",
    "llm_translation = translate_with_llm(chinese_text)\n",
    "\n",
    "# RAG\n",
    "rag_translation = translate_with_rag(chinese_text, vector_store)\n",
    "\n",
    "\n",
    "print(chinese_text)\n",
    "\n",
    "print(\"\\nLLM\")\n",
    "\n",
    "print(llm_translation.content)\n",
    "\n",
    "print(\"\\nRAG\")\n",
    "print(rag_translation.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of translation results\n",
    "\n",
    "Evaluation of translation results using BLEU and TER scores.\n",
    "Considering the addition of COMET and GPT for further assessment.\n",
    "Aiming to improve accuracy and quality in translation evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Œ **Translation Quality Evaluation (BLEU & TER Scores)**\n",
      "\n",
      "â•’â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â••\n",
      "â”‚    â”‚ Category      â”‚ Text                                           â”‚ BLEU   â”‚ TER   â”‚\n",
      "â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡\n",
      "â”‚  0 â”‚ Source Text   â”‚ è¿™ä¸ªäº§å“åœ¨å¸‚åœºä¸Šå¾ˆå—æ¬¢è¿ã€‚                     â”‚ -      â”‚ -     â”‚\n",
      "â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚  1 â”‚ Translation 1 â”‚ This product is very popular in the market.    â”‚ 0.0    â”‚ 800.0 â”‚\n",
      "â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚  2 â”‚ Translation 2 â”‚ This product is well received in the market.   â”‚ 0.0    â”‚ 800.0 â”‚\n",
      "â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚  3 â”‚ Source Text   â”‚ äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜ä¸–ç•Œã€‚                         â”‚ -      â”‚ -     â”‚\n",
      "â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚  4 â”‚ Translation 1 â”‚ Artificial intelligence is changing the world. â”‚ 0.0    â”‚ 600.0 â”‚\n",
      "â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚  5 â”‚ Translation 2 â”‚ AI is transforming the world.                  â”‚ 0.0    â”‚ 500.0 â”‚\n",
      "â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚  6 â”‚ Source Text   â”‚ å¤©æ°”å¾ˆå¥½ï¼Œæˆ‘ä»¬å»å…¬å›­å§ã€‚                       â”‚ -      â”‚ -     â”‚\n",
      "â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚  7 â”‚ Translation 1 â”‚ The weather is great, let's go to the park.    â”‚ 0.0    â”‚ 900.0 â”‚\n",
      "â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚  8 â”‚ Translation 2 â”‚ It's nice outside, let's visit the park.       â”‚ 0.0    â”‚ 700.0 â”‚\n",
      "â•˜â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•›\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\herme\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import nltk\n",
    "import sacrebleu\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "\n",
    "#  BLEU\n",
    "def calculate_bleu(reference, candidate):\n",
    "    return round(sacrebleu.sentence_bleu(candidate, [reference]).score, 3)\n",
    "\n",
    "\n",
    "# TER\n",
    "def calculate_ter(reference, candidate):\n",
    "    ter_metric = sacrebleu.metrics.TER()\n",
    "    return round(ter_metric.corpus_score([candidate], [[reference]]).score, 3)\n",
    "\n",
    "\n",
    "json_file_path = \"data/translations_comparison.json\"\n",
    "\n",
    "\n",
    "def load_json_data(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "\n",
    "translations_data = load_json_data(json_file_path)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(translations_data)\n",
    "\n",
    "results = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    source_text = row[\"source_text\"]\n",
    "    translation_1 = row[\"translation_1\"]\n",
    "    translation_2 = row[\"translation_2\"]\n",
    "\n",
    "    # translation_1 evaluation\n",
    "    bleu_1 = calculate_bleu(source_text, translation_1)\n",
    "    ter_1 = calculate_ter(source_text, translation_1)\n",
    "\n",
    "    # translation_2 evaluation\n",
    "    bleu_2 = calculate_bleu(source_text, translation_2)\n",
    "    ter_2 = calculate_ter(source_text, translation_2)\n",
    "\n",
    "    results.append(\n",
    "        {\n",
    "            \"Category\": \"Source Text\",\n",
    "            \"Text\": source_text,\n",
    "            \"BLEU\": \"-\",\n",
    "            \"TER\": \"-\",\n",
    "        }\n",
    "    )\n",
    "    results.append(\n",
    "        {\n",
    "            \"Category\": \"Translation 1\",\n",
    "            \"Text\": translation_1,\n",
    "            \"BLEU\": bleu_1,\n",
    "            \"TER\": ter_1,\n",
    "        }\n",
    "    )\n",
    "    results.append(\n",
    "        {\n",
    "            \"Category\": \"Translation 2\",\n",
    "            \"Text\": translation_2,\n",
    "            \"BLEU\": bleu_2,\n",
    "            \"TER\": ter_2,\n",
    "        }\n",
    "    )\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def display_results(dataframe):\n",
    "    print(\"\\nğŸ“Œ **Translation Quality Evaluation (BLEU & TER Scores)**\\n\")\n",
    "    print(tabulate(dataframe, headers=\"keys\", tablefmt=\"fancy_grid\"))\n",
    "\n",
    "\n",
    "display_results(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-opentutorial-HDS-w_h3-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
